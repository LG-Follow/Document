\documentclass[conference]{IEEEtran}
\usepackage{titlesec}
\usepackage{float}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{url}



\ifCLASSINFOpdf
\hyphenation{op-tical net-works semi-conduc-tor}


\begin{document}

\title{LG Follow}


\author{\IEEEauthorblockN{Mingyu Jung}
\IEEEauthorblockA{\textit{Dept. of Information Systems} \\
\textit{Hanyang Univ.}\\
Seoul, Republic of Korea\\
alsrb595@hanyang.ac.kr
}
\and
\IEEEauthorblockN{Taegeon Park}
\IEEEauthorblockA{\textit{Dept. of Information Systems} \\
\textit{Hanyang Univ.}\\
Seoul, Republic of Korea \\
qkrxorjs@hanyang.ac.kr
}
\and
\IEEEauthorblockN{Gyudong Kim}
\IEEEauthorblockA{\textit{Dept. of Information Systems} \\
\textit{Hanyang Univ.}\\
Seoul, Republic of Korea \\
gyudong1594@hanyang.ac.kr
}
\and
\IEEEauthorblockN{Mingeun Kim}
\IEEEauthorblockA{\textit{Dept. of Information Systems} \\
\textit{Hanyang Univ.}\\
Seoul, Republic of Korea \\
alsrms0206@hanyang.ac.kr
}

}


\maketitle




\begin{abstract}
    Imagine an office worker getting ready for work in the morning, listening to music or the news through an speaker. During the morning routine, they might wash up in the bathroom, make coffee in the kitchen, have breakfast, choose clothes from the closet, and get dressed. For someone who moves between rooms so frequently, it's almost impossible to catch 100\% of the audio output from a stationary speaker.
    
    We are introducing technology that called LG Follow allows sound to follow the user, creating an environment where they can hear audio in any part of the house with LG appliances equipped with speakers.
    
    Using a Raspberry Pi and PIR sensors, the system detects the user's location and seamlessly transfers the sound to the area where the user is currently located. For instance, if they leave the living room and enter the bedroom, the speaker in the living room will stop, and the speaker in the bedroom will automatically take over, seamlessly continuing the audio experience. MQTT protocol manages the communication between Raspberry Pi and the speaker.
    
    Additionally, we provide an app called Sound Sketch that turns children's drawings into songs using generative AI. When a child draws a picture, the Sound Sketch will create a song based on their own picture. Through a trained AI model, the drawings will be transformed into prompts, and those prompts will be turned into music. With LG Follow, kids can enjoy listening to their own music as they move around the house, making each moment truly unique and magical.

\end{abstract}





\begin{table}[h!]
\centering
\caption{: Role Assignments}
\begin{tabular}{|c|c|p{3.5cm}|}
\hline
\textbf{Roles} & \textbf{Name} & \textbf{Task description and etc.} \\
\hline
Backend Developer & Mingyu Jung & The backend developer would implement the logic to process location data from the Raspberry Pi and PIR sensors, ensuring the user’s movement through the house is accurately tracked and relayed to the speaker. Ensure that when the user moves between rooms, the appropriate speaker is activated, and the previous one is turned off, all in real-time. Handle communication between the Raspberry Pi, PIR sensors, and speaker using the MQTT protocol, ensuring compatibility between the smart home appliances and devices. \\
\hline

\end{tabular}
\end{table}

\vspace{0.8cm}

\begin{table}[h!]
\centering
\begin{tabular}{|c|c|p{3.5cm}|}
\hline
\textbf{Roles} & \textbf{Name} & \textbf{Task description and etc.} \\
\hline
Frontend Developer & Taegeon Park & The role of a frontend developer includes designing the frontend architecture and creating user interfaces and experiences using Figma. It involves collaborating with the backend team to discuss and implement required features while ensuring seamless integration with the server. The responsibilities also extend to reviewing designs and functionalities, keeping the user and consumer in focus to deliver an optimal user experience. \\
\hline
Backend Developer & Gyudong Kim & AI developer utilizes openai models BLIP to generate prompts from input images. To ensure the safety of children, AI developers fine-tune the BLIP model so that inappropriate prompts are not created. Once the prompts are generated, AI developers use the Suno API to create songs from these prompts. Also AI developers are responsible for designing and building databases to store and manage various types of data, such as user information, home appliances, and the generated drawings and songs, ensuring efficient integration and management within the application. Implement a database to store user preferences, drawings, and song files generated by Sound Sketch.\\
\hline
Frontend Developer & Mingeun Kim & The frontend developer would design the interface for the LG Follow app, ensuring that both LG Follow and Sound Sketch are intuitive and user friendly. This includes creating buttons and layouts for turning speakers on/off and uploading drawings to generate songs. The developer will focus on helping LG Follow and Sound Sketch features, enabling users to control speakers in different rooms and upload or manage children's drawings in the app.  \\
\hline
\end{tabular}
\end{table}


\IEEEpeerreviewmaketitle

\section{Introduction}

\subsection{Motivation}

\subsubsection{We wanted to create an experience where the sound follows the user, ensuring uninterrupted audio no matter where they are in the house. With LG appliances equipped with speakers, the user can now enjoy continuous sound as they move from room to room, eliminating the frustration of missing important parts of the music or news.
Our motivation goes beyond just convenience, it’s about creating an immersive and seamless audio experience that adapts to the user's movement. By integrating AI and smart home appliances, we aim to make daily life smoother and more enjoyable.}
\

\subsubsection{Our motivation for making Sound Sketch from a desire to bring children's creativity to life in a magical way and to strengthen the bond between parents and their children. Children often express their imagination through drawing, and we wanted to elevate that experience by transforming their artwork into personalized music. With the power of generative AI, a simple drawing becomes a unique, original song, giving children a new way to connect with their creations.
What makes this experience even more special is the opportunity for parents and children to collaborate. By drawing together and hearing their joint artwork turned into a song, they can build memories and strengthen their connection through a shared creative process. With LG Follow, these songs can accompany them throughout the house, creating a sense of togetherness and joy, wherever they go.
Our goal is to seamlessly blend creativity and technology, offering families a fun and interactive way to bond while engaging with music that feels personal and meaningful. Every moment becomes truly unique and magical as they hear their imagination come to life.}


\
\subsubsection{We've combined the LG Follow and Sound Sketch features into a single app, allowing users to experience both functionalities seamlessly in one place. With LG Follow, users can easily turn off the speaker in any appliance if they prefer not to have sound in a specific room. Meanwhile, Sound Sketch transforms children's drawings into songs, bringing their creativity to life in a fun and engaging way. The app ensures everything is accessible and simple to control, offering a smooth, personalized, and user-friendly experience.}


\
\
\
\subsection{Problem Statement (client’s needs)}

In today’s homes, speakers are commonly used to play music or news, but they are limited by their stationary nature. For someone who moves frequently between rooms during their morning routine—such as washing up in the bathroom, making coffee in the kitchen, or getting dressed in the bedroom—it becomes nearly impossible to catch all the audio from a single fixed speaker. This leads to a frustrating, interrupted experience where important parts of the audio are missed.\\

LG Follow solves this problem by allowing sound to follow the user throughout the house. As users move from room to room, LG appliances equipped with speakers provide continuous audio, eliminating gaps and ensuring they never miss a moment of music or news. This technology is designed to deliver a seamless and immersive audio experience, adapting to the user's movements to enhance their daily routine.\\

Additionally, we identified a need for families to engage creatively, leading to the development of Sound Sketch, an app that transforms children's drawings into personalized songs using generative AI. Children often express their imagination through drawings, and this feature elevates that creativity by turning their artwork into unique songs. It also offers parents and children the opportunity to bond through collaboration, creating memories as they hear their joint artwork come to life as music. By integrating LG Follow, these songs can follow the family throughout the house, adding a layer of joy and togetherness.\\

Both features, LG Follow and Sound Sketch, are integrated into the single app for ease of use, allowing users to control audio and manage drawings in one convenient place. \\

 
\subsection{Research on Any Related Software}

\subsubsection{Contrastive Language-Image Pre-training (CLIP): CLIP, developed by OpenAI, is a model trained on a large dataset of text and images to understand and associate visual and textual inputs. It enables users to perform tasks such as image search or classification using natural language prompts without task-specific fine-tuning, utilizing zero-shot capabilities. CLIP works by encoding images and text into a shared high-dimensional space where related pairs are closer together and unrelated pairs are further apart through a contrastive learning approach. While it demonstrates strong generalization capabilities, CLIP can exhibit biases present in its training data and may face challenges with nuanced or context-specific tasks.}

\
\subsubsection{Sonos (Multi-Room Speaker System): Sonos is a leading brand in multi-room audio systems. Sonos allows users to control audio in various rooms through a smartphone app, letting users sync music in different areas of the house. However, unlike LG Follow, Sonos requires manual control for changing rooms or selecting where to play audio. It does not automatically follow the user based on their movement.}

\
\subsubsection{NVIDIA Fugatto: NVIDIA Fugatto is an AI technology that generates audio from text prompts. By inputting a text description, Fugatto can create audio content that matches the provided prompt. For example, if you input 'calm and serene morning,' Fugatto will generate soft and peaceful music or nature sounds. Fugatto focuses on converting text into music, creating audio that matches the emotional tone or atmosphere described in the text.}
\

\subsubsection{Google Nest and Amazon Echo: Google Nest and Amazon Echo provide smart home automation, including voice-activated music playback. They can control music in various rooms and offer smart integrations with other appliances. However, users need to manually control playback across different speakers, and the sound doesn’t seamlessly follow the user. }

\
\
\subsubsection{Melobytes: Melobytes is one tool where users can upload an image, and the system generates music from it using algorithms tailored to the visual data. It transforms the picture into unique sound compositions that reflect the visual input.}
\

\subsubsection{Img2Prompt (Anakin.ai): This tool uses AI to analyze an image and generate a text prompt that encapsulates its key visual features. The generated prompt can then be used for various creative projects, like digital art or content creation.}
\

\subsubsection{GoEnhance AI: This platform allows users to upload an image, and its AI algorithms automatically generate a text prompt based on the visual content. These prompts can be used with tools like DALL-E or Midjourney to generate new AI-created images based on the original photo's characteristics.}
\


\


\section{Requirements}

\subsection{Log In}

\subsubsection{Initial Screen: When the app launches, the initial screen displayed to users is the login screen, providing access for existing users. This screen serves as the primary interface for user access, where users can input their credentials (ID and password) to authenticate.}

\
\subsubsection{User Input: The user is required to enter their credentials, including:}
\begin{itemize}
    \item ID Entry: The user must enter a unique identifier associated with their account. This ID serves as the primary authentication element linked to their account access.\\
    \item Password Entry: The password is a private passphrase known only to the user, ensuring account protection. The password field masks the entered characters to prevent visibility, and only the user is aware of this passphrase.\\
    \item ID and Password Format Validation: When the user enters the ID and password, basic format validation is conducted. For instance, if the ID is in email format, it verifies the presence of required elements like '@' and '.com'. The password field may also enforce minimum length and include special characters or numbers to strengthen security.\\
\end{itemize}

\subsubsection{Validation and Authentication}
\begin{itemize}
    \item Password Hashing: Once the password is entered, it is hashed using the SHA-256 hashing algorithm upon reaching the server. This process converts the entered password into a unique hash value, ensuring that the original plaintext password is neither transmitted nor stored, thus enhancing security. SHA-256 provides a secure hash that is difficult to reverse-engineer, protecting the password from unauthorized access even in the event of data leaks.\\
    \item ID Verification: After hashing, the system checks if the entered ID exists in the database.
    \begin{itemize}
        \item If the ID exists: The system compares the hash of the entered password with the stored hash in the database.
        \begin{itemize}
            \item If the hashes match: A 'Login Successful' message is displayed, indicating successful authentication and granting access to the user, who is then directed to the home or main interface.\\
            \item If the hashes do not match: An 'Incorrect password' message is displayed, prompting the user to re-enter their password. This message helps prevent unauthorized access by notifying the user of a password mismatch and requiring a new attempt.\\
        \end{itemize}
        \item If the ID does not exist: The system displays a message such as 'The entered ID does not exist,' informing the user of an incorrect entry. This allows the user to correct their entry and retry the login process.\\
    \end{itemize}
\end{itemize}


\subsection{Fine-tuning the BLIP Model}

\subsubsection{Dataset Collection}
\begin{itemize}
    \item Utilize the Flickr30k dataset available on Hugging Face, which includes images paired with their corresponding captions. Download the dataset using the Hugging Face Datasets library and prepare it for training preprocessing.\\
\end{itemize}

\subsubsection{Data Processing}
\begin{itemize}
    \item Preprocess the dataset to ensure it works smoothly with the BLIP(Bootstrapped  Language-Image  Pretraining) model. Convert all inputs into a format the model can understand. Adjust text data so all sequences are the same length and create markers to identify real data versus padding. Standardize the image data format and organize captions into a list to prepare for training in batches.\\
\end{itemize}

\subsubsection{Training Process}
\begin{itemize}
    \item Initialize the BLIP model and processor. Use a DataLoader to batch the preprocessed data and train the model. Compute and backpropagate the loss for each batch, updating the model parameters. Save the trained model and processor after completing the specified number of epochs.\\
\end{itemize}

\subsection{Prompt Generation from Image}

\subsubsection{User Input}
\begin{itemize}
    \item After successful login, users can provide images through the app. These images can either be photos from their gallery or drawings created by the users.\\
\end{itemize}

\subsubsection{Image Storage}
\begin{itemize}
    \item The images are stored in Amazon S3, and a URL is retrieved. The URL is securely stored in the RDS along with information about the user who uploaded the image.\\
\end{itemize}

\subsubsection{Generating Prompt}
\begin{itemize}
    \item The backend server sends a request to the AI model's server to generate a prompt using the trained BLIP model. The generated prompt is stored in the RDS along with information about the image.\\
\end{itemize}


\subsection{Music Generation from Prompt}

\subsubsection{Prompt Transfer}
\begin{itemize}
    \item The backend server sends the stored prompt to the Suno API, requesting the generation of basic music.\\
\end{itemize}

\subsubsection{Generating Music}
\begin{itemize}
    \item Suno API generates music using the provided prompt. It sends information about the generated music to the backend server. This information includes the music URL, playback duration, and creation date.\\
\end{itemize}

\subsubsection{Song Storage}
\begin{itemize}
    \item The backend server stores the received information in the RDS along with the prompt that was used to generate the music.\\
\end{itemize}

\subsubsection{View Music}
\begin{itemize}
    \item When a user requests to view music, backend server provides information about the music. This includes the music URL, the URL of the image that was used to generate the prompt, and the playback duration.\\
\end{itemize}

\subsubsection{Playing Music}
\begin{itemize}
    \item Users can play the generated music in real-time using the app. The duration of the music track is displayed in seconds.\\
\end{itemize}


\subsection{Speaker-to-Speaker Connection}
\begin{itemize}
    \item  System Configuration
\begin{itemize}
    \item The Raspberry Pi plays a central role in controlling music playback on speakers by utilizing a motion detection sensor. The Spring Boot server acts as the central control hub, collecting motion detection information and managing music playback commands for the speakers.\\
    \item The Spring Boot server sends audio playback commands to the Raspberry Pi, which uses VLC Media Player to play music through the speakers. During this process, the server transmits data including the playback URL, starting point (currentTime), and additional information to ensure synchronized audio playback across all speakers.\\
\end{itemize}
\end{itemize}

\begin{itemize}
    \item Expanding Device Compatibility
\begin{itemize}
    \item The Raspberry Pi is designed to synchronize audio playback across various types of speakers. When a user enters a specific room, the PIR sensor detects the motion and informs the Spring Boot server, which then sends a music playback command to the corresponding Raspberry Pi in that room.\\
    \item All speakers receive the same music URL and playback starting point, allowing seamless audio playback even when the user moves between rooms. Music playback is automatically controlled based on the Raspberry Pi’s detected actions. When the user leaves the room, the server is notified, and music playback is stopped.\\
\end{itemize}
\end{itemize}


\subsection{User Location Tracking for Audio Control}
\begin{itemize}
    \item Location Data Collection via PIR Sensors
\begin{itemize}
    \item PIR sensors in each room detect user movement and transmit data to Raspberry Pi in real-time, allowing accurate location tracking.\\
    \item Accurate Location Tracking: The PIR sensors provide accurate, room-level tracking, allowing the system to respond dynamically to the user’s movements and adjust audio playback accordingly. This setup enables the audio to follow the user throughout different rooms, ensuring that the music or audio content is always accessible in the user’s immediate vicinity.\\
\end{itemize}
\end{itemize}
\begin{itemize}
    \item Location-Based Speaker Control
\begin{itemize}
    \item Automatic Speaker Activation and Deactivation:
When a user moves from one room to another, the Raspberry Pi's PIR sensor detects the movement and sends a command to the central Spring Boot server. Based on this command, the server deactivates the speaker in the previous room and activates the speaker in the current room, continuing music playback from the same playback position. This ensures that music only plays in the room where the user is present, providing a seamless audio experience without interruptions.\\
\end{itemize}
\end{itemize}
\begin{itemize}
    \item Speaker Control and Audio Transition
\begin{itemize}
    \item Real-Time Audio Switching Using the MQTT Protocol:
The Raspberry Pi communicates motion detection events and playback control commands with the Spring Boot server using the MQTT protocol. When motion is detected, the Raspberry Pi in the active room adjusts the playback position and resumes music without restarting the process. This minimizes latency and allows smooth audio transitions between rooms.\\
    \item Seamless Multi-Speaker Coordination:
As the user moves between rooms, music playback seamlessly switches between speakers. Each room’s Raspberry Pi synchronizes the playback position using VLC, ensuring consistent audio output. This adjustment allows music to dynamically follow the user, providing a continuous and immersive listening experience.\\
\end{itemize}
\end{itemize}

\subsection{Location-Based Sound Transition}

\subsubsection{Real-time Streaming with MQTT Protocol}
\begin{itemize}
    \item MQTT Configuration for Each Room’s Speaker
\begin{itemize}
    \item  Each room’s speaker is configured to receive audio data via the MQTT (Message Queuing Telemetry Transport) protocol. As the user moves between rooms, the Raspberry Pi utilizes MQTT to seamlessly switch audio playback to the appropriate speaker based on the user’s location. The MQTT broker serves as the intermediary, ensuring smooth audio data transfer between speakers. Each speaker subscribes to specific topics, and as the user moves, the Raspberry Pi publishes the audio data to the relevant topic, enabling the transition of audio between rooms without interruption.\\
\end{itemize}
\end{itemize}
\begin{itemize}
    \item Seamless Streaming
\begin{itemize}
    \item MQTT, being a lightweight message protocol, is optimized for real-time data transmission, allowing audio to be delivered rapidly and reliably. As the user transitions from one room to another, the MQTT broker ensures that the audio data is routed to the correct speaker based on the user’s location. Using MQTT’s QoS (Quality of Service) levels, the protocol guarantees that data is delivered reliably, ensuring a continuous streaming experience without interruption.\\
\end{itemize}
\end{itemize}

\subsubsection{Audio Data Transfer}
\begin{itemize}
    \item Communication Management Using the MQTT Protocol
\begin{itemize}
    \item Raspberry Pi devices are directly connected to speakers, and all Raspberry Pis are configured to subscribe to specific topics on the MQTT broker. The Spring Boot server also subscribes to the same MQTT topics, enabling bidirectional communication between the server, Raspberry Pis, and speakers.\\
    \item When user movement is detected, the Raspberry Pi sends an MQTT message, which is received by the Spring Boot server. The server then sends music playback information back to the relevant Raspberry Pi, instructing its connected speaker to play the music. This setup enables real-time communication between devices, ensuring efficient and synchronized audio data transfer.\\
\end{itemize}
\end{itemize}

\begin{itemize}
    \item Enhanced Audio Experience
\begin{itemize}
    \item With MQTT’s QoS features, audio data is transmitted reliably and without loss. The MQTT broker plays a central role in managing and propagating messages between speakers. As the user moves, the broker ensures that the audio stream is transitioned smoothly from one speaker to the next, delivering an uninterrupted listening experience.
\end{itemize}
\end{itemize}

\subsection{Speaker On/Off Functionality}
\begin{itemize}
    \item User Preference Storage
\begin{itemize}
    \item Centralized User Preference Management: User preferences, such as enabling or disabling music in specific rooms, are stored on a central server and communicated to the Raspberry Pi via MQTT protocol.\\
\end{itemize}
\end{itemize}
\begin{itemize}
    \item Speaker Control
\begin{itemize}
    \item Raspberry Pi uses the Matter protocol to control music playback according to user preferences, turning music on or off in designated rooms.\\
\end{itemize}
\end{itemize}

\subsection{Music CRUD}
\begin{itemize}
    \item The Spring Boot server processes the request and ensures real-time streaming of the music, allowing users to listen to the song as soon as it's generated.\\
    \item For storage and long-term management of the generated music, the metadata and music links are handled by Amazon RDS, which communicates with a MySQL database to store information such as the song title, date of creation.\\
    \item Users can perform CRUD operations on the generated music.
\begin{itemize}
    \item Create: Saving the generated music to the Amazon RDS
    \item Read: Streaming the saved music from RDS and retrieving metadata from the database for display in the app.\\
    \item Update: Modifying the song’s metadata or regenerating the music by submitting a new drawing.\\
    \item Delete: Removing the music file from RDS and its metadata from the MySQL database.\\
\end{itemize}
\end{itemize}


\section{Development Environment}

\subsection{Hardware Development Environment}

\subsubsection{Raspberry Pi}
\begin{figure}[h!]
    \centering
    \includegraphics[width=0.5\linewidth]{image/RaspberryPi.png}
\caption{Rasberry Pi}
    \label{fig:enter-label}
\end{figure}

\noindent The Raspberry Pi is a small computer commonly used in various programming and IoT projects. Its efficient and cost-effective design makes it popular for home automation and IoT environments.\\

Role:
\begin{itemize}
    \item IoT Device Control: The Raspberry Pi serves as the main device for controlling IoT devices in this project. It connects with multiple sensors and actuators (e.g., PIR sensor, temperature sensor), collects data, processes it, and sends it to the system.\\
    \item Using MQTT Protocol: The Raspberry Pi communicates with other devices or servers through the MQTT protocol, allowing real-time monitoring and control of IoT device states.\\
    \item Serving as a Matter Bridge: The Raspberry Pi is configured as a Matter bridge to facilitate communication with devices compatible with the Matter Protocol. This setup enables it to communicate with various Matter-compliant IoT devices, allowing centralized control and monitoring of each device via the Spring Boot server. The Matter bridge acts as a communication hub for IoT devices, ensuring interoperability among devices within the same network.\\
    \item Network Management and Processing: Through network connectivity, the Raspberry Pi connects to the Spring Boot server or the Matter Protocol to transmit and receive data and to process various commands.\\
\end{itemize}

Technical Features:
\begin{itemize}
    \item Compact Size and Low Power Consumption: Ideal for environments with space and power constraints.\\
    \item Expandability: The GPIO pins allow easy connection to various sensors and actuators, providing flexibility for various IoT projects.\\
    \item Matter Bridge Integration: Acting as a Matter bridge, the Raspberry Pi operates as an integration point for interacting with Matter-supported devices. This enables other Matter-compatible devices to connect through the Raspberry Pi, ensuring smooth communication.\\
    \item Supports Various Languages: Raspberry Pi can be controlled using multiple programming languages such as Python, C++, and Java, offering developers a high degree of flexibility.\\
\end{itemize}
    

\subsubsection{Matter Protocol}
\begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\linewidth]{image/Matter.png}
    \caption{Matter}
    \label{fig:enter-label}
\end{figure}
\noindent The Matter Protocol is a communication protocol developed to enhance interoperability among smart home and IoT devices. Supported by major IoT device manufacturers, Matter ensures compatibility between devices from different manufacturers within a smart home ecosystem.\\

Role:
\begin{itemize}
    \item Provides Interoperability among IoT Devices: With the Matter Protocol, various IoT devices within the same network can communicate seamlessly. This enables the devices used in the project to interact smoothly with one another.\\
    \item Standardized Data Transmission: The Matter Protocol offers a standardized method for data transmission, simplifying data management and transfer for developers.\\
    \item Enhanced Security Features: Matter strengthens security by employing encryption for data transmission between devices and an authentication system that only allows approved devices to connect.\\
\end{itemize}

Technical Features:
\begin{itemize}
    \item Multi-Platform Support: Matter supports various network technologies such as Wi-Fi, Ethernet, Thread, and BLE, allowing flexible configurations suited to the environment.\\
    \item Simplified Development Process: Matter streamlines communication protocols, making integration easier for developers and ensuring compatibility across a wide range of IoT devices.
    \item High-Performance Security: It provides security based on authentication, ensuring that data transmission between IoT devices is securely protected.\\
\end{itemize}

\subsubsection{PIR Sensor}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.5\linewidth]{image/PirSensor.jpeg}
    \caption{PIR Sensor}
    \label{fig:enter-label}
\end{figure}
\noindent A PIR (Passive Infrared) sensor is used to detect motion and is commonly employed in security and home automation systems. It senses infrared signals emitted by the human body to determine motion and can monitor user presence within a specific area.\\

Role:
\begin{itemize}
    \item User Detection and Music Control: The PIR sensor detects users within a room and triggers actions like playing or stopping music when certain conditions are met. When a user is detected, it sends a signal to the Spring Boot server to turn on the music. If the user leaves the detection range or after a certain period, it can be configured to stop the music automatically.\\
    \item Energy Efficiency Maintenance: The PIR sensor helps in reducing unnecessary power consumption by detecting activity in a particular area. When no user is detected, it automatically turns off devices like music or lighting to save energy.\\
    \item Real-time Status Transmission: It sends real-time movement data to the Spring Boot server, which can then use this information to control other IoT devices based on user location.\\
\end{itemize}

Technical Features:
\begin{itemize}
    \item Low Power Consumption: The PIR sensor consumes minimal power as it only sends a signal when the detection state changes.\\
    \item Easy Installation and Connection: It can be easily connected to the GPIO pins of control devices like Raspberry Pi and can be handled with simple signal processing.\\
    \item Instant Response Time: The PIR sensor is suitable for applications that require immediate feedback as it quickly detects human movement.\\
    \item Wide Detection Range: It generally provides a broad detection angle, allowing it to sense movement throughout an entire room.\\
\end{itemize}


\subsection{Software Develepment Platform}

\subsubsection{Linux}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.7\linewidth]{image/Linux.jpeg}
    \caption{Linux}
    \label{fig:enter-label}
\end{figure}

\noindent Linux, an operating system based on UNIX, is known for supporting multiple users, multi-tasking, and multi-threading, making it highly suitable for development environments. As an open-source OS, it has been widely distributed and modified for various needs, with popular distributions like Ubuntu. Linux excels in server environments, desktop applications, and embedded systems development due to its flexibility, performance, and robust security features. Its extensive command-line utilities make it particularly adept for working with development boards and IoT devices, allowing seamless integration with hardware. Additionally, Linux’s strong community support ensures quick troubleshooting and continuous enhancements, making it an excellent choice for IoT development and large-scale software projects.\\

\subsubsection{Windows}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\linewidth]{image/Windows.png}
    \caption{Windows}
    \label{fig:enter-label}
\end{figure}

\noindent Windows, developed by Microsoft, is one of the most widely used operating systems globally, known for its compatibility with a vast range of software applications and hardware devices. Its graphical user interface and accessibility make it versatile for personal, business, and development use. Windows supports multi-tasking and multi-threading, which enhances its capability for running complex applications and handling high-demand development tasks. With tools like Visual Studio, Windows provides comprehensive support for app development across multiple platforms, including desktop, web, and mobile applications. Windows Subsystem for Linux (WSL) allows developers to use Linux command-line tools and utilities directly on Windows, making it an adaptable choice for cross-platform development. Furthermore, Windows offers strong support for gaming and multimedia applications due to DirectX and hardware acceleration capabilities. Its enterprise-level security options, combined with Microsoft’s extensive documentation and community support, make Windows a reliable operating system for both general-purpose computing and advanced development environments. \\

\subsubsection{macOS}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.4\linewidth]{image/macOS.jpg}
    \caption{macOS}
    \label{fig:enter-label}
\end{figure}

\noindent macOS, developed by Apple and based on UNIX, is widely recognized for its user-friendly interface and stability, making it a preferred operating system for developers, particularly in design, media, and software development environments. Its robust integration with Apple hardware ensures optimized performance and energy efficiency, which is essential for seamless application testing and development. macOS includes powerful command-line utilities and developer tools such as Xcode, which supports app development for the Apple ecosystem, including iOS, macOS, watchOS, and tvOS. Additionally, the macOS environment provides strong support for multi-tasking and multi-threading, and its UNIX-based architecture offers compatibility with various development frameworks and programming languages, making it highly adaptable to web, mobile, and cloud applications. macOS’s extensive developer community, combined with Apple’s regular updates, ensures high security standards, efficient troubleshooting, and consistent performance, making it an ideal choice for both individual developers and large-scale development teams. \\


\subsubsection{MQTT Protocol}

\noindent MQTT (Message Queuing Telemetry Transport) is a lightweight messaging protocol designed primarily for IoT (Internet of Things) and M2M (Machine to Machine) communication. It is optimized for environments with limited bandwidth and unreliable networks, making it ideal for real-time data transmission between small devices and servers.\\

\subsection{Language \& Framework}

\subsubsection{Spring Boot}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\linewidth]{image/SpringBoot.png}
    \caption{Spring Boot}
    \label{fig:enter-label}
\end{figure}

\noindent Spring Boot is a lightweight Java-based backend framework that simplifies the process of quickly developing standalone web applications. It reduces the complexity of configuring the Spring Framework by including embedded web servers, such as Tomcat or Jetty, enabling the application to run with minimal additional setup in both development and production environments.\\

Role:
\begin{itemize}
\item Web Application Development: Facilitates the rapid development of standalone web applications.\\
\item Auto-configuration: Provides automatic configuration for various Spring features without needing XML or Java Config classes.\\
\item  Dependency Management: Simplifies dependency configuration with Spring Boot Starter, boosting development efficiency. \\
\item Security and Authentication: Easily integrates with Spring Security, allowing for streamlined implementation of authentication and authorization. \\
\item Asynchronous Processing and Scheduling: Ideal for IoT, mobile, and cloud applications, enabling easy development of REST APIs, asynchronous processing, and scheduling functionalities. \\
\end{itemize}

Technical Features: 
\begin{itemize}
    \item Embedded Server: Bundles web servers such as Tomcat, Jetty, and Undertow, eliminating the need for separate configurations.\\
    \item Automatic Configuration: Automatically sets up necessary features, streamlining application setup.\\
    \item Support for Various Environments: Easily adaptable from local development to cloud deployment.\\
    \item MQTT Support: Enables MQTT messaging with libraries like Eclipse Paho MQTT Client, allowing Spring Boot applications to publish and subscribe to MQTT messages.\\
\end{itemize}



\subsubsection{Java}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.5\linewidth]{image/Java.png}
    \caption{Java}
    \label{fig:enter-label}
\end{figure}

\noindent Java is an object-oriented programming language known for its platform independence, allowing applications to run consistently across different operating systems. With the motto Write Once, Run Anywhere, Java achieves cross-platform compatibility through the JVM (Java Virtual Machine), enabling stable and efficient application development. \\

Role:
\begin{itemize}
    \item Server-side Logic Development: Java’s reliability makes it widely used for server applications.\\ 
    \item Multithreading and Asynchronous Processing: Java's multithreading and asynchronous processing capabilities are ideal for IoT systems that require real-time data handling.\\
    \item Large-scale System Operation: Thread management, garbage collection, and robust libraries enable Java to handle high-traffic server applications effectively.\\
\end{itemize}

Technical Features:
\begin{itemize}
    \item Object-Oriented Programming: High reusability and scalability, making maintenance straightforward.\\
    \item Platform Independence with JVM: Allows consistent code execution across various platforms via the JVM.\\
    \item Extensive Standard Libraries: Provides libraries for networking, databases, file handling, and more, supporting efficient application development.\\
    \item Reliability and Performance: Ensures stability in large-scale systems and guarantees performance in multithreaded environments.\\
\end{itemize}



\subsubsection{Python}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.9\linewidth]{image/Python.png}
    \caption{Python}
    \label{fig:enter-label}
\end{figure}


\noindent Python is a widely used interpreted language known for its simplicity, readability, and versatility across various applications and platforms. Its ease of use and concise syntax significantly reduce development time and minimize errors, making it a popular choice for developers.\\

Role:
\begin{itemize}
    \item Cross-Platform Compatibility: Python is a cross-platform language that can run on various operating systems (Linux, Windows, Mac) with minimal modifications, providing flexibility and efficient deployment.\\
    \item Data Processing and Manipulation: Its strengths in string processing and data manipulation make Python ideal for applications involving text and image processing, data analysis, and scientific computing.\\
    \item Automation and Scripting: Python's readability and flexibility make it suitable for automation tasks, enabling the development of scripts and tools for repetitive tasks and efficient workflows.\\
\end{itemize}

Technical Features:
\begin{itemize}
    \item Concise and Readable Syntax: Python’s straightforward syntax enhances code readability and reduces development time, contributing to rapid prototyping and easier debugging.\\
    \item Extensive Libraries: Python offers a rich ecosystem of libraries, including Pandas, NumPy, and OpenCV, which simplify complex operations such as data analysis, machine learning, and image processing.\\
    \item Community and Documentation: Python boasts a large and active community, providing a wealth of resources, support, and libraries that streamline development.\\
\end{itemize}

\subsubsection{Flask}
\begin{figure}[h!]
    \centering
    \includegraphics[width=0.6\linewidth]{image/Flask.png}
    \caption{Flask}
    \label{fig:enter-label}
\end{figure}

\noindent Flask is a lightweight web framework for Python, known for its simplicity, flexibility, and suitability for small to medium-sized web applications and APIs. Flask provides a straightforward foundation for building web applications with minimal setup.\\

Role:
\begin{itemize}
    \item RESTful API Development: Flask is optimized for creating RESTful APIs, providing tools for handling HTTP requests and responses, which is ideal for applications requiring data exchange in formats like JSON.\\
    \item Integration with Python Models: Flask can easily integrate with Python-based machine learning models, making it simple to serve model predictions and data processing results to client applications.\\
    \item Customizable and Modular: Flask allows developers to include only the components needed for a project, creating a lean and efficient development environment.\\
\end{itemize}

Technical Features:
\begin{itemize}
    \item Lightweight and Flexible: Designed to be minimalistic, Flask allows developers to build web applications without unnecessary features, ensuring a flexible and tailored environment.\\
    \item Powerful Routing and Request Handling: Flask’s built-in support for routing and handling HTTP methods makes it suitable for building APIs and web services.\\
    \item Rich Ecosystem of Extensions: Flask supports numerous extensions, allowing for easy integration of features like authentication, database connections, and caching.\\
\end{itemize}


\subsubsection{Flutter}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.3\linewidth]{image/Flutter.png}
    \caption{Flutter}
    \label{fig:enter-label}
\end{figure}

\noindent Flutter is an open-source UI toolkit developed by Google, allowing developers to create natively compiled applications for mobile, web, and desktop from a single codebase. It is known for its expressive UI, fast development cycles, and ability to create visually appealing applications. By using Dart, a language optimized for building mobile applications, Flutter offers a seamless and efficient development experience with extensive community support and a rich library of widgets.\\

Role:
\begin{itemize}
    \item Cross-platform Development: Flutter provides a seamless way to create applications that work consistently across multiple platforms, including iOS, Android, web, and desktop, from one codebase. This greatly simplifies development and reduces costs.\\
    \item Rich and Customizable UI Design: Flutter's widget-based framework allows developers to create highly customizable UIs with complex animations, ensuring a native-like experience and high performance for both simple and intricate designs.\\
    \item Component-based Architecture: Flutter's widget-centric architecture encourages modular code that is easy to reuse, manage, and scale. Developers can create complex UIs by composing and nesting widgets.\\
    \item Expressive Declarative UI: Flutter uses a declarative approach to building UIs, making the code more readable, intuitive, and responsive to changes in state.\\
\end{itemize}

Technical Features:
\begin{itemize}
    \item Dart Language: Flutter leverages Dart, a powerful, easy-to-learn language optimized for mobile and desktop apps with strong performance and efficient memory management.\\
    \item Extensive Widget Library: Flutter offers a vast collection of built-in widgets that are fully customizable, enabling developers to create UIs that conform to platform-specific designs or have a unique, custom look.
    \item Hot Reloading: Allows developers to make changes to the code and see the results instantly without losing application state, enhancing productivity and speeding up development cycles.\\
    \item Native Integration and Flexibility: Flutter allows seamless integration with platform-specific APIs and services, offering flexibility to access native features and deliver a native-like user experience.\\
    \item IoT-related System Development: Flutter is well-suited for use alongside the latest technologies. Consider using Flutter when developing IoT (Internet of Things) solutions. It enables efficient integration of smart devices with user interfaces, facilitating the creation of high-performance IoT systems.
\end{itemize}


\subsection{Software \& AI model In Use}

\subsubsection{BRIP}

\noindent BLIP (Bootstrapping Language-Image Pre-training) is a cutting-edge AI model that enables unified vision-language understanding and generation. By training on a large dataset of image-text pairs, BLIP can perform diverse tasks such as image captioning, visual question answering, and text-guided image generation.\\

Role: 
\begin{itemize}
    \item Image Captioning: BLIP generates descriptive captions for images, providing a textual representation of visual content, which is useful for accessibility and content categorization.\\
    \item Visual Question Answering: BLIP interprets visual data to answer questions about images, offering real-time assistance and context comprehension for visual-based tasks.\\
    \item Text-Guided Image Generation: BLIP creates or modifies images based on textual prompts, bridging the gap between visual creativity and text-based control.\\
\end{itemize}

Technical Features:
\begin{itemize}
    \item Zero-shot Learning: BLIP’s zero-shot capabilities allow it to adapt to new tasks without additional training data, making it versatile across various applications.\\
    \item Specialized Language Training: By training on datasets with images and Korean captions, BLIP can generate Korean prompts, making it suitable for localized applications and non-English language tasks.\\
    \item Enhanced Vision-Language Bridging: BLIP effectively integrates textual and visual data, enabling it to process and produce outputs that combine both modalities seamlessly.\\
\end{itemize}

\subsubsection{Suno API}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.6\linewidth]{image/Suno.png}
    \caption{Suno API}
    \label{fig:enter-label}
\end{figure}

\noindent Suno API is an innovative AI model that enables the automatic generation of songs based on text prompts. It integrates natural language processing and music generation technologies to transform text into fully realized songs, including lyrics, melodies, and vocals. By interpreting the text prompt, Suno API generates custom songs that align with the user’s specific requirements in terms of genre, emotion, and style.\\

Role:
\begin{itemize}
\item Song Lyrics Generation: Based on a text prompt, Suno API generates song lyrics automatically. For example, users can provide a theme or emotion, and the system will create relevant lyrics for a song.\\
\item Music Composition: Suno API can generate accompanying music for the lyrics by interpreting the text prompt. It produces melodies, chords, and harmonies that align with the requested genre or mood.\\
\item Vocal Synthesis: Once the song’s lyrics and music are generated, Suno API synthesizes vocals, delivering high-quality, human-like singing. The vocals are crafted to match the mood, tone, and style defined in the prompt.\\
\end{itemize}

Technical Features:
\begin{itemize}
    \item Advanced Text-to-Music Translation: Suno API combines natural language processing (NLP) and music generation technologies to convert text-based prompts into full-fledged songs, including lyrics, melodies, and vocals.\\
    \item Emotion and Mood Reflection: The system can analyze the emotion conveyed in the prompt (e.g., sadness, joy, love) and generate music that reflects this emotion, adjusting the melody, tempo, and vocal tone accordingly.\\
    \item Zero-shot Learning: Suno API leverages zero-shot learning capabilities to generate songs in various genres and styles without requiring additional training data. It can adapt to new prompts and create custom songs immediately.\\
\end{itemize}


\subsubsection{Amazon S3}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\linewidth]{image/AmazonS3.png}
    \caption{Amazon S3}
    \label{fig:enter-label}
\end{figure}

\noindent Amazon Simple Storage Service (Amazon S3) is a highly scalable object storage service known for its industry-leading data availability, security, and performance. Amazon S3 provides a robust infrastructure for storing and managing large volumes of data, particularly useful for media files such as images and music.\\

Role:
\begin{itemize}
    \item File Storage: Stores generated music files and uploaded image files in S3, with Flask generating music files that the Spring Boot server saves to S3, providing clients with URLs for file download or streaming.\\
    \item Cloud Storage: Manages large data volumes efficiently, including user-related images and audio files.\\
    \item Data Management: Used for organizing temporary or outdated data, as well as for backups. Access permissions can be configured to restrict file access to specific users.\\
\end{itemize}

Technical Features:
\begin{itemize}
    \item Scalability: S3 automatically scales to accommodate large volumes of data as file counts increase.\\
    \item Reliability: Offers high durability, ensuring data is securely stored.\\
    \item Flexible Access Management: Access Control Lists (ACLs) and bucket policies allow for detailed permission settings.\\
\end{itemize}

\subsubsection{MySQL}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.5\linewidth]{image/MySQL.png}
    \caption{MySQL}
    \label{fig:enter-label}
\end{figure}

\noindent MySQL is a widely used open-source relational database management system (RDBMS) known for its stability, performance, and ability to handle large datasets efficiently. Its robust functionality makes it ideal for managing data-intensive applications, including those that track user locations, manage media files, and facilitate device interactions.\\

Role:
\begin{itemize}
    \item Data Storage: Stores and manages user information, generated music metadata (title, creation date, etc.), and music request data. This enables the system to store a wide variety of data permanently for retrieval as needed.\\
    \item Data Integrity Assurance: Ensures data consistency and integrity through transactions and foreign keys, maintaining stability even when multiple users access data simultaneously.\\
    \item CRUD Operations: Supports Create, Read, Update, and Delete operations through integration with the Spring Boot application.\\
\end{itemize}

Technical Features:
\begin{itemize}
\item SQL-Based: Uses standard SQL queries, making data management straightforward.\\
\item Scalability: Efficiently manages large transactions and data with scalable architecture.\\
\item Reliability: Provides strong backup and recovery capabilities to ensure data security.\\
\end{itemize}

\subsubsection{Amazon RDS (Relational Database Service)}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.5\linewidth]{image/AmazonRDS.png}
    \caption{Amazon RDS}
    \label{fig:enter-label}
\end{figure}

\noindent Amazon RDS is AWS’s managed relational database service, handling database server management and maintenance, allowing developers to focus on data-related tasks rather than setup and maintenance.\\

Role: 
\begin{itemize}
    \item MySQL Server Hosting: Supports MySQL and other database engines, making it easy to set up and manage MySQL servers. In this project, RDS manages user information, music metadata, and music requests.\\
    \item Automated Management: Handles database backups, security patches, and software updates automatically, reducing database management burdens.\\
    \item Scalability: Supports scale-up/down as traffic or storage needs change. For high read performance, Read Replicas can be added.\\
\end{itemize}

Specific Functions:
\begin{itemize}
    \item Persistent Data Storage: The RDS MySQL server stores user-related data, music metadata, and music requests, ensuring reliable data management even with high request volumes.\\
    \item Data Backup and Recovery: Performs regular backups automatically, with automatic recovery capabilities to ensure data integrity and reliability.\\
    \item High Availability: Multi-AZ deployment replicates databases across availability zones, providing high availability and fast recovery in case of failures.\\
\end{itemize}

Technical Features:
\begin{itemize}
    \item Automatic Backups: Regular backups enable point-in-time recovery.\\
    \item Security: Supports VPC isolation, AWS IAM integration, and data encryption via AWS Key Management Service (KMS).\\
    \item Monitoring and Alerts: Integrates with Amazon CloudWatch for real-time database performance monitoring and notifications for any issues.\\
\end{itemize}

Integration with RDS:
\begin{itemize}
    \item Spring Boot: The Spring Boot project connects directly with AWS RDS MySQL, leveraging Spring Data JPA for efficient database interactions. Database URL, username, and password are configured using the RDS endpoint.\\
    \item RDS MySQL Setup: After creating a MySQL instance in the RDS console, its endpoint and credentials are used to connect the Spring Boot application.\\
\end{itemize}

\subsubsection{Visual Studio Code}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.5\linewidth]{image/VScode.png}
    \caption{VS Code}
    \label{fig:enter-label}
\end{figure}

\noindent Visual Studio Code (VS Code) is a lightweight and highly customizable code editor developed by Microsoft. Known for its versatility and extensive extension ecosystem, VS Code supports a wide range of programming languages and development environments, making it a popular choice for developers across various fields.\\

Role:
\begin{itemize}
    \item Code Editing and Development: VS Code provides a streamlined, efficient environment for writing, editing, and managing code in multiple languages. It offers a powerful, customizable interface that supports development workflows from simple scripts to large projects.\\
    \item Extension Support: With thousands of extensions available, VS Code allows developers to add language support, frameworks, linters, debuggers, and tools specific to their project needs, enhancing productivity and flexibility.\\
    \item Remote Development: VS Code’s remote development feature allows users to work on projects hosted on remote servers or in containers, enabling efficient collaboration and resource utilization.\\
\end{itemize}

Technical Features:
\begin{itemize}
    \item Lightweight and Fast: Designed for speed and efficiency, VS Code is a lightweight editor that quickly adapts to various development environments without significant resource usage.\\
    \item Integrated Debugging and Git: VS Code includes built-in debugging and Git support, streamlining the development and version control process within a single interface.\\
    \item Highly Customizable: Through JSON configuration files, settings, and an extensive extension library, VS Code allows for deep customization to meet individual development needs.\\
\end{itemize}


\subsubsection{Android Studio}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.5\linewidth]{image/AndroidStudio.jpg}
    \caption{Android Studio}
    \label{fig:enter-label}
\end{figure}

\noindent Android Studio is Google’s official integrated development environment for Android app development, offering a comprehensive suite of tools and resources tailored specifically for Android platforms.\\

Role:
\begin{itemize}
    \item Emulator for Testing: It provides a fast and feature-rich emulator, simulating a wide range of Android devices and configurations for thorough testing without needing physical devices.\\
    \item Extensive Testing Tools: Android Studio includes a variety of testing tools and frameworks that support automated and manual testing, enhancing app quality and stability.\\
    \item Easy SDK Access: The IDE includes Android SDK and essential tools out-of-the-box, allowing developers to start building Android applications immediately.
\end{itemize}

Technical Features:
\begin{itemize}
    \item Integrated Emulator: Fast, powerful emulator to test app functionality across device configurations.\\
    \item Comprehensive Testing Support: Tools for unit, UI, and integration testing.\\
    \item Code Inspection and Lint: Automates code quality checks and flags potential issues.\\
\end{itemize}



\subsubsection{Xcode}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.5\linewidth]{image/Xcode.jpg}
    \caption{Xcode}
    \label{fig:enter-label}
\end{figure}

\noindent Xcode is Apple’s official IDE for developing applications on iOS, macOS, watchOS, and tvOS, offering a complete suite of tools and resources to streamline development for Apple’s platforms.\\

Role:
\begin{itemize}
    \item Apple Platform Development: Xcode is essential for creating applications for Apple’s ecosystem, providing all necessary tools to develop iOS and macOS applications quickly and efficiently. \\
    \item Built-In Simulator: The simulator allows for testing applications without needing a physical device, supporting various iOS versions and device types.\\
    \item Storyboard and App Structure Visualization: The storyboard feature enables developers to see the structure of the app at a glance, aiding in the systematic design of complex applications.\\
\end{itemize}

Technical Features:
\begin{itemize}
    \item Drag-and-Drop Interface Builder: Simplifies UI design with visual placement and Auto Layout.\\
    \item Comprehensive Preview Options: Preview and adjust for multiple devices and screen sizes.\\
\end{itemize}


\subsubsection{Figma}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.5\linewidth]{image/Figma.jpg}
    \caption{Figma}
    \label{fig:enter-label}
\end{figure}

\noindent Figma is a cloud-based design and prototyping tool used for creating interactive and collaborative design experiences. Known for its flexibility and real-time collaboration features, Figma allows designers and teams to work together seamlessly from anywhere.\\

Role:
\begin{itemize}
    \item UI/UX Design: Figma provides a robust platform for designing user interfaces and experiences, with tools to create detailed wireframes, mockups, and high-fidelity designs.\\
    \item Prototyping: Enables the creation of interactive prototypes that allow designers to simulate user flows and test interactions, providing a clear vision of the final product.\\
    \item Collaboration: Real-time collaboration allows multiple team members to work simultaneously on the same file, streamlining the feedback process and reducing delays.\\
\end{itemize}

Technical Features:
\begin{itemize}
    \item Developer-Friendly Inspect Tool: Developers can access design specifications, CSS code, and assets directly, ensuring a smooth design-to-code transition.\\
    \item Interactive Prototyping and Animation: Offers tools to create interactive animations and transitions, making it easy to visualize and test user interactions.\\
    \item Cloud-Based and Cross-Platform: Figma operates in the cloud, accessible from any browser and supporting both Windows and macOS, making it highly versatile and collaborative.\\
\end{itemize}


\subsubsection{Docker}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\linewidth]{image/Docker.jpg}
    \caption{Docker}
    \label{fig:enter-label}
\end{figure}

\noindent Docker is an open-source platform that allows applications to be containerized, enabling consistent management of environments across development and production. It helps developers and operations teams build and deploy applications more efficiently. By running applications in isolated containers, Docker minimizes issues that can arise during the deployment process.\\

Role:
\begin{itemize}
    \item Application Deployment: Docker reduces the gap between development and production environments, making it easy to deploy and run applications. This ensures applications can be consistently run across different environments.\\
    \item Environment Isolation: Docker runs each application in an isolated container, resolving dependency issues between systems. It ensures that multiple applications do not conflict with each other.\\
    \item CI/CD Integration: Docker is useful in continuous integration and deployment (CI/CD) environments, enabling fast and stable deployment of code changes.\\
\end{itemize}

Technical Features:
\begin{itemize}
    \item Containerization: Docker packages the application and its environment into a single unit, allowing it to run consistently across different platforms.\\
    \item Lightweight: Docker is more lightweight than virtual machines, using fewer system resources and allowing for faster startup and shutdown.\\
    \item Networking and Storage: Docker makes it easy to manage networking and storage settings, facilitating smooth communication between containers.\\
    \item Scalability: Docker can run hundreds of containers simultaneously, making it easy to scale and manage large applications.\\
\end{itemize}

Integration with Docker:
\begin{itemize}
    \item Spring Boot: Docker can containerize Spring Boot applications, automating deployment and minimizing the differences between environments. Spring Boot applications run within Docker containers, ensuring consistency between development and production environments.\\
    \item Flask: Flask applications can also be containerized using Docker. This enables consistent execution across different environments, improving efficiency in deployment and maintenance.\\
\end{itemize}


\subsubsection{Apache Kafka}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\linewidth]{image/Kafka.png}
    \caption{Apache Kafka}
    \label{fig:enter-label}
\end{figure}

\noindent Apache Kafka is a high-performance, distributed streaming platform used to handle large-scale, real-time data streams. Kafka is widely used for messaging systems, event sourcing, log aggregation, and building data pipelines. Built on a distributed architecture, Kafka provides high scalability and durability.\\

Role:
\begin{itemize}
    \item Data Streaming: Kafka is used to process real-time data streams. It efficiently transmits data from producers to consumers in real-time, handling large volumes of data flow.\\
    \item Event Sourcing: Kafka plays a crucial role in event-driven systems by sequentially recording and storing events, enabling subsequent processing of these events.\\
    \item Data Pipelines: Kafka provides a pipeline for managing data flow between different systems, allowing seamless integration between multiple systems exchanging data.\\
    \item Real-Time Analytics: Kafka is useful for real-time data analysis, enabling quick processing and extraction of insights from continuous data streams.\\
\end{itemize}

Technical Features:
\begin{itemize}
    \item Distributed Architecture: Kafka is designed with a clustered setup, providing high availability and fault tolerance. Data is distributed across multiple servers, ensuring continuous operation even in case of failures.\\
    \item Scalability: Kafka can handle thousands of partitions, allowing it to scale efficiently even as data volume grows.\\
    \item Durability: Kafka ensures data durability by continuously storing data on disk, preventing data loss and allowing for recovery in case of failures.\\
    \item High Throughput: Kafka is known for its high throughput, capable of processing millions of messages per second.\\
\end{itemize}

Integration with Kafka:
\begin{itemize}
    \item Spring Boot: Kafka integrates well with Spring Boot applications, enabling the building of asynchronous, message-driven systems. The Spring Kafka library simplifies interactions with Kafka within Spring Boot projects.\\
    \item Microservices: Kafka is ideal for service-to-service communication in microservices architectures. It allows services to communicate by sending and receiving events through Kafka, reducing tight coupling between services.\\
    \item Real-Time Processing: Kafka can be used in combination with real-time processing frameworks like Apache Spark or Apache Flink to enable real-time data analytics and processing.\\
\end{itemize}



\subsubsection{Pytorch}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\linewidth]{image/PyTorch.png}
    \caption{PyTorch}
    \label{fig:enter-label}
\end{figure}

\noindent PyTorch is an open-source deep learning framework that provides a flexible and efficient platform for building and training machine learning models, widely used in both academic research and production environments.\\

Role:
\begin{itemize}
    \item Deep Learning Framework: PyTorch is essential for developing machine learning and deep learning models, offering tools that support both research and production. It provides efficient and flexible mechanisms for building complex models, from neural networks to reinforcement learning agents.\\
    \item GPU Acceleration: With native support for CUDA, PyTorch accelerates training using GPUs, making it well-suited for working with large-scale datasets and deep neural networks.\\
\end{itemize}

Technical Features:
\begin{itemize}
    \item Tensor Operations: PyTorch offers a powerful tensor library for multi-dimensional arrays and matrices, similar to NumPy, with GPU acceleration for efficient computations on large datasets.\\
    \item Pretrained Models and Ecosystem: PyTorch provides access to a wide range of pretrained models and related libraries, such as torchvision for computer vision, torchaudio for audio processing, and torchtext for NLP tasks, enabling rapid deployment of state-of-the-art solutions.\\
\end{itemize}

\vspace{3cm}

\section{Specification}

\subsection{Initial Screen}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.5\linewidth]{image/InitialScreen.png}
    \caption{Initial Screen}
    \label{fig:enter-label}
\end{figure}

\noindent When the user launches the app, the initial screen displays the 'LG Follow' logo and the 'Follow your Experience' tagline for 2–3 seconds. After a brief delay, the screen transitions smoothly to the login page.\\

\clearpage

\subsection{Log In}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.5\linewidth]{image/Login.png}
    \caption{Log In}
    \label{fig:enter-label}
\end{figure}

\subsubsection{ID Input}
\begin{itemize}
    \item Explanation: 'Email ID or Phone number ID' to guide the user on the input type.\\
    \item Input Format: Accepts either an email address or phone number.\\
    \item Validation: Checks if the input follows the correct format
\begin{itemize}
    \item Email: Format like user@example.com\\
    \item Phone number: Format like 01012345678\\
\end{itemize}
\end{itemize}

\subsubsection{Password Input}
\begin{itemize}
    \item Explanation: Displays 'Password' as guidance for the user.\\
    \item Input Format: Accepts text for password entry, displayed as '\textbullet' symbols to conceal the input.\\
\end{itemize}

\subsubsection{Log In}
\begin{itemize}
    \item Action: When clicked, the button attempts to log in with the provided ID and password.
\begin{itemize}
    \item On Success: Redirects to the main screen.\\
    \item On Failure: Shows an error message ('The entered ID or password is incorrect').\\
\end{itemize}
\end{itemize}

\subsubsection{Log In Process}
\begin{itemize}
    \item Input Check: When the log in button is clicked, the ID and password are validated against database records.\\
    \item Password Hashing: The entered password is hashed using the SHA-256 algorithm before being compared to the stored hash in the database.\\
    \item Authentication and Response
\begin{itemize}
    \item Success: On successful log in, the user is redirected to the main screen.\\
    \item Failure: If log in fails, an error message ('The entered ID or password is incorrect') is displayed.\\
\end{itemize}
\end{itemize}



\subsection{Main Page}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.5\linewidth]{image/Main.png}
    \caption{Main Page}
    \label{fig:enter-label}
\end{figure}



\subsubsection{Home Application Power On/Off}

\begin{itemize}
    \item Power Button: Turns individual appliances On/Off. (In the On state, the power button appears green, and in the Off state, it appears as a red button.\\
    \item When the user clicks the power button for a specific appliance, the application records the device's status (On/Off) in the database or local storage.\\
    \item Upon status change, the application sends a command to the appliance to toggle its power state.\\
    \item If the device is currently on, clicking the button will turn it off, and if it is off, clicking the button will turn it on.\\
\end{itemize}\\

\subsubsection{LG Follow Function On/Off}
\begin{itemize}
    \item Speaker Button: Controls the LG Follow function for audio playback in the room where the appliance is located.(urns individual appliances On/Off. (In the On state, the speaker button is displayed, and in the Off state, it appears on the speaker button with a strikethrough.)\\
    \item User Location Detection
\begin{itemize}
    \item PIR Sensors: PIR (Passive Infrared) sensors installed in each room detect the user’s movement. When the user enters a room, the PIR sensor in that room activates and sends the location data to the Raspberry Pi.\\
\end{itemize}
\end{itemize}
\begin{itemize}
    \item Data Collection and Transmission by Raspberry Pi
\begin{itemize}
    \item Raspberry Pi: Acts as a central hub that collects location data from all room PIR sensors. As the user moves from room to room, the Raspberry Pi updates the user’s location in real time.\\
    \item MQTT Protocol: Raspberry Pi communicates with other room speakers via the Matter protocol to control audio output based on the user’s current location.\\
\end{itemize}
\end{itemize}
\begin{itemize}
    \item Audio Transition
\begin{itemize}
    \item When the user enters a new room, the Raspberry Pi sends a command to stop audio playback in the previous room’s speaker and switch the audio to the speaker in the current room.\\
    \item This setup allows the user to hear audio naturally in each new room as they move throughout the house.\\
\end{itemize}
\end{itemize}
\begin{itemize}
    \item User Control Options for LG Follow
\begin{itemize}
    \item LG Follow On/Off for Specific Devices: Users can enable or disable the Follow feature for specific appliances in particular rooms, allowing more customized control over where audio follows them.\\
\end{itemize}
\end{itemize}

\subsubsection{Add Application Button ('+' Button)}
\begin{itemize}
    \item Opens a QR code scanning screen to add a new appliance.\\
    \item When the user clicks the appliance button, the application navigates to the QR code scanning screen.\\
    \item The user can scan a QR code to register a new appliance, which will then be added to the home screen for control.\\
\end{itemize}

\vspace{2cm}

\subsection{Device Registration}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.5\linewidth]{image/QR0.png}
    \caption{Device Registration}
    \label{fig:enter-label}
\end{figure}
\begin{figure}[h!]
    \centering
    \includegraphics[width=0.5\linewidth]{image/QR.png}
    \caption{QR Scan}
    \label{fig:enter-label}
\end{figure}

\begin{itemize}
    \item QR Scanning Frame: A square frame located in the center of the screen where users align the QR code.\\
    \item QR Code Recognition and Registration
\begin{itemize}
    \item Automatic Scanning: When a QR code is aligned within the scanning frame, the app automatically recognizes it without requiring a separate confirmation button.\\
    \item Validation: Once the QR code is scanned, the app verifies if it corresponds to a valid LG appliance model and matches the format stored in the database.\\
    \item Registration: If validated, the appliance is registered to the user’s account and linked to the LG Follow feature.\\
\end{itemize}
\end{itemize}
\begin{itemize}
    \item Navigation Upon Successful Scan
\begin{itemize}
    \item Automatic Transition: Once the QR code is successfully recognized and the appliance is registered, the app automatically navigates the user back to the main screen.\\
    \item Confirmation Message: Upon returning to the main screen, a brief confirmation message ('Appliance registered successfully') may appear to inform the user of successful registration.\\
\end{itemize}
\end{itemize}
\begin{itemize}
    \item Error Handling: If the QR code is invalid or unrecognized, an error message appears ('Invalid QR code. Please try again').\\
    \item     Through these features, users can easily control appliance power, manage room-specific LG Follow audio settings, and add new appliances.\\
\end{itemize}


\subsection{Menu Page}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.5\linewidth]{image/Menu.png}
    \caption{Menu Page}
    \label{fig:enter-label}
\end{figure}

\noindent User starts on the home screen and presses the menu button located on the bottom navigation bar, they open the menu page. From there, if the user navigates to the Life section and selects the Sound Sketch button, the app transitions to the Sound Sketch screen, providing them access to that feature. \\

\subsection{Sound Sketch Initial Screen}


\begin{figure}[h!]
    \centering
    \includegraphics[width=0.5\linewidth]{image/SoundSketch1.png}
    \caption{Enter Sound Sketch}
    \label{fig:enter-label}
\end{figure}

\noindent 
When the user navigates to the menu page and presses the Sound Sketch button, the screen transitions smoothly to the Sound Sketch initial screen. The initial screen displays the 'Sound Sketch' logo at the center along with a clean design. After a brief moment, the screen transitions seamlessly to the main functionality of the Sound Sketch feature. \\

\clearpage

\subsection{Sound Sketch Main Page}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.5\linewidth]{image/SoundSketch2.png}
    \caption{Sound Sketch Main Page}
    \label{fig:enter-label}
\end{figure}

\subsubsection{Quick Playlist Section}

\begin{itemize}
    \item The Quick Playlist section, located at the top, displays a list of previously created drawings along with their associated music.
\begin{itemize}
    \item Thumbnail: Each record is shown as a thumbnail that displays the user’s actual drawing.\\
    \item Label: A label is displayed below each thumbnail, showing the song title and creation date to help users easily identify each record.\\
\end{itemize}
    \item Functionality: Users can select a previous drawing to view the related music information or to play the music.\\
    \item Saved Playlist: When a user completes and saves a drawing, it is added to the record section. The actual drawing is displayed as a thumbnail in the record section, and the metadata for the generated music is stored in the MySQL database via Spring Boot.\\
    \item Music Streaming: When a user selects a specific record thumbnail, the associated music is streamed in real-time, allowing the user to listen to it immediately.\\
\end{itemize}

\subsubsection{Temporary Storage Section}

\begin{itemize}
    \item The Temporary Storage section is located at the middle and shows the drawings that the user started but hasn't finished yet.
\begin{itemize}
    \item Thumbnail: The thumbnail displays the user’s current drawing in a large square, making it easy to recognize.\\
\end{itemize}
    \item Functionality: Even if the app is closed or the user switches tasks, the ongoing drawing is saved. When the user taps this thumbnail, they can resume working on the saved drawing.\\
    \item Image Temporary Storage: When a user temporarily saves a drawing, the image data is stored in a fast-access storage system. This ensures quick access and enhances the user experience by allowing seamless continuation during the drawing process.\\
    \item Temporary Data Recovery: When the user selects the saved drawing from the Temporary Storage section, the data is retrieved, allowing the user to resume their work without interruption.\\

\end{itemize}

\subsubsection{New Start Section}

\begin{itemize}
    \item When the user drags the 'Drag Up to Start' section at the bottom of the screen, they can begin a new drawing.\\
    \item Functionality 
\begin{itemize}
    \item Transition to Drawing Page: By dragging the button up, the user is taken to a new page where they can start a new drawing.\\
    \item Temporary Data Reset: When a new project is started, the existing temporary data is either reset or updated to prepare for saving the new drawing.\\

\end{itemize}
\end{itemize}    

\clearpage

\subsection{Sketch Page }

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.5\linewidth]{image/SoundSketch3.png}
    \caption{Sketch Page}
    \label{fig:enter-label}
\end{figure}

\subsubsection{Canvas Section}
\begin{itemize}
    \item The white rectangle area in the center of the screen serves as a canvas where users can draw freely. This section is dedicated to allowing users to create and edit their drawings.\\
    \item Drawing Canvas: An interactive canvas where users can draw using various lines and colors.\\
\end{itemize}

\subsubsection{Submit Button}
\begin{itemize}
    \item Allows users to submit the completed drawing to the server for music generation.\\
\end{itemize}

\subsubsection{Delete Button}
\begin{itemize}
    \item Provides an option to delete the current drawing on the canvas.\\
\end{itemize}

\subsubsection{File Icon}
\begin{itemize}
    \item Sound Sketch allows you to create songs by attaching image files.\\
\end{itemize}

\subsubsection{Back Icon}
\begin{itemize}
    \item Allows users to return to the Sound Sketch main page.\\
    \item When clicked, the current drawing is temporarily saved, ensuring it is securely stored before navigating back to the Sound Sketch main page.\\
\end{itemize}

\vspace{3cm}

\section{Architecture Design}

\subsection{Overall Architecture}

\begin{figure}[h!]
    \centering
    \includegraphics[width=1\linewidth]{image/Arichitecture.png}
    \caption{Overall Architecture}
    \label{fig:enter-label}
\end{figure}

 \noindent The overall software architecture consists of three parts; frontend, backend and AI.\\

 \subsubsection{Frontend}
 \begin{itemize}
     \item Framework: Flutter\\
     \item Design tool: Figma\\
     \item Summary of features:
\begin{itemize}
    \item Provides a canvas screen that allows users to draw and send their drawings to the backend.\\
    \item Offers toggle buttons to turn LG appliances power and speakers On/Off.\\
    \item Enables QR scanning to register LG appliances in the LG Follow app.\\
    \item Provides a user interface to access previously created songs.\\
    \item Displays an interface to view unfinished drawings.\\
\end{itemize}
 \end{itemize}

 \subsubsection{Backend}
\begin{itemize}
    \item Web Framework: Spring Boot\\
    \item Database: My SQL, RDS\\
    \item Data storage: AWS S3\\
    \item API: Suno API\\
    \item Application tool: Apache Kafka, Docker\\
    \item Summary of features:
\begin{itemize}
    \item Generates songs based on prompts.\\
    \item Stores user-drawn illustrations and the generated songs.\\
    \item It enables sound transmission between speakers.\\
\end{itemize}
\end{itemize}

\subsubsection{AI}
\begin{itemize}
    \item Framework: PyTorch\\
    \item Web Framework: Flask\\
    \item AI Model: BLIP (Bootstrapping Language-Image Pre-training)\\
    \item Summary of features: Extracts prompts from user-drawn illustrations.\\
\end{itemize}


\subsection{Overall Directory Organization}

\begin{figure}[h!]
    \centering
    \includegraphics[width=1\linewidth]{image/Directory.png}
    \caption{Directory Organization}
    \label{fig:enter-label}
\end{figure}

The LG Follow project consists of four GitHub repositories: Frontend, Backend, AI, and Document. Each repository plays a distinct role in the project’s architecture and development.\\

The Frontend repository is responsible for developing the user interface and application for LG Follow. It includes code and resources to support multiple platforms, such as Android and iOS. The lib directory contains the core business logic and UI components of the frontend application, handling essential functionalities like screen navigation, state management, and user interactions. Additionally, configuration and dependency management files, such as pubspec.yaml and analysis options.yaml, are included to ensure efficient project maintenance.\\
\

The Backend repository is responsible for server-side logic in LG Follow. This repository includes all the necessary files to handle user requests, data processing, and other backend operations. The main implementation is located in the src directory, while Gradle build scripts (build.gradle, settings.gradle) and Docker configuration files (compose.yaml) support deployment and build automation.\\

The AI repository is dedicated to developing and managing LG Follow’s artificial intelligence functionalities. It includes trained models (project\_directory/models/trained\_model), core scripts like main.py for executing AI processes, and train\_model.py for model training. Dependencies for AI tasks are managed through the requirement.txt file. Additionally, the configs and utils directories provide configuration files and utility scripts, ensuring a modular and well-structured AI system.\\

The Document repository is responsible for managing the documentation of the LG Follow project. It includes the final project document in PDF format, LG\_Follow.pdf, and the LaTeX source file, LG\_Follow.tex, used to create it.\\

\subsection{Module 1: Backend}

\subsubsection{Purpose}
\noindent To implement the backend, we used Spring Boot to build an application, streamlining the development process. For database management, we adopted Amazon RDS, which provided a centralized and scalable solution. This setup enabled the team to collaborate effectively and handle data efficiently throughout the project. The centralized database allowed shared access and simplified maintenance tasks, significantly improving overall productivity. Additionally, we integrated the MQTT protocol to facilitate real-time communication with Raspberry Pi. This implementation allowed for efficient data exchange and control between the backend and the device.\\

\subsubsection{Functionality}
\noindent The LG Follow server executes tasks requested by users through the frontend and Raspberry Pi. It processes data and stores the corresponding values in the database. When a user requests song creation, the server generates the song, saves it to the database, and delivers it to the frontend. Additionally, it ensures smooth sound transmission between the Raspberry Pi devices using the MQTT protocol.\\ 

\subsubsection{Location of source code: }
\url{https://github.com/LG-Follow/Back_End}\\

\clearpage

\begin{table}[h!]
\caption{Backend Directory Organization}
\def\arraystretch{1.4} \small
    \begin{tabular}{|p{4.1cm}|p{4.1cm}|}
        \hline
        \textbf{Directory} & \textbf{File Name} \\ \hline
        Root & .gitattributes \par .gitignore 
        \par build.gradle
        \par compose.yaml
        \par gradlew \par gradlew.bat \par settings.gradle\\ \hline
        gradle/wrapper& gradle-wrapper.jar \par gradle-wrapper.properties\\ \hline
        src/main/java/com/example  \par /lgfollow\_server & LgFollowServer\par Application.java \\ \hline
        src/main/java/com/example \par /lgfollow\_server/component & MqttMessageListener.java \\ \hline
        src/main/java/com/example \par /lgfollow\_server/config & KafkaConsumerConfig.java \par KafkaProducerConfig.java \par MqttConfig.java \par RestConfig.java \par S3Config.java \\ \hline
        src/main/java/com/example \par /lgfollow\_server/controller & ImageController.java \par SongController.java \par UserDeviceController.java \par UsersController.java \\ \hline
        src/main/java/com/example\par /lgfollow\_server/dto & ImageSendDto.java \par PromptGetDto.java \par SongDto.java \par SunoApiResponse.java \par UserDto.java \\ \hline
        src/main/java/com/example \par /lgfollow\_server/gateway & MqttGateway.java \\ \hline
        src/main/java/com/example \par /lgfollow\_server/model & Device.java \par Image.java \par Prompt.java \par Song.java \par SongRequest.java \par UserDevice.java \par UserDeviceId.java \par Users.java \\ \hline
        src/main/java/com/example \par /lgfollow\_server/repository & ImageRepository.java \par PromptRepository.java \par SongRepository.java \par UserDeviceRepository.java \par UsersRepository.java \\ \hline
        src/main/java/com/example\par /lgfollow\_server/security & SecurityConfig.java \par WebConfig.java \\ \hline
        src/main/java/com/example \par /lgfollow\_server/service & ImageService.java \par MqttPublisherService.java \par SongSendService.java \par SongService.java \par UserDeviceService.java \par UsersService.java \\ \hline
        src/main/resources & application.properties \par application.yml \\ \hline
        src/test/java/com/example \par /lgfollow\_server & LgFollowServer\par ApplicationTests.java \\ \hline
    \end{tabular}
\end{table}


\subsubsection{Class Component}

\begin{itemize}
    \item LgFollowServerApplication.java: This is a file for Spring Boot Application entrypoint. \\
    \item lgfollow\_server/component: This package contains components that handle reusable logic.
    \begin{itemize}
        \item MqttMessageListener.java: A component that listens for incoming MQTT messages and processes them. 
    \end{itemize}
    \item lgfollow\_server/config: This package contains configurations for external systems and application settings.
    \begin{itemize}
        \item KafkaConsumerConfig.java: Configuration for Kafka consumers, defining properties for consuming messages from Kafka topics. \\
        \item KafkaProducerConfig.java: Configuration for Kafka producers, specifying properties for sending messages to Kafka topics. \\
        \item MqttConfig.java
\begin{itemize}
    \item Configuration for connecting to the MQTT broker, including client settings and connection parameters.\\
    \item Dependency: org.springframework.integration:spring-integration-mqtt:6.3.5\\
    \item Broker Setup: A local Mosquitto broker is used for managing MQTT message exchanges.\\
\end{itemize}
        \item RestConfig.java: Configuration for REST API clients, including base URLs and request/response customization. \\
        \item S3Config.java: Configuration for connecting to AWS S3, including bucket names, credentials, and storage options. \\
    \end{itemize}
    \item lgfollow\_server/controller: This package contains controllers that manage API endpoints for handling user requests.
    \begin{itemize}
        \item ImageController.java: Handles API endpoints related to image upload, retrieval, and processing. \\
        \item SongController.java: Manages API requests for song creation, storage, and retrieval. \\
        \item UserDeviceController.java: Handles device-related actions, such as registration, updates, and communication. \\
        \item UsersController.java: Manages user-related endpoints for profile management and data access. \\
    \end{itemize}
    \item lgfollow\_server/dto: This package contains Data Transfer Objects (DTOs) for exchanging structured data between layers.
    \begin{itemize}
        \item ImageSendDto.java: Data Transfer Object (DTO) for sending image-related data between layers. \\
        \item PromptGetDto.java: DTO for receiving prompt-related data. \\
        \item SunoApiResponse.java: DTO representing the response structure from external Suno API. \\
        \item UserDto.java: DTO for transferring user data, such as authentication or profile information.
    \end{itemize}
    \item lgfollow\_server/gateway : This package contains gateway interfaces for external communication.
    \begin{itemize}
        \item MqttGateway.java: A gateway interface for sending messages through the MQTT broker. \\
    \end{itemize}
    \item lgfollow\_server/model: This package contains entity classes that represent the database structure and application models.
    \begin{itemize}
        \item Device.java: Entity representing a device registered by a user, including its attributes. \\
        \item Image.java: Entity representing images uploaded in the application. \\
        \item Prompt.java: Entity for storing prompts submitted by users for various images. \\
        \item Song.java: Entity for storing metadata and content related to songs created or retrieved. \\
        \item SongRequest.java: Entity representing a user's request for song creation. \\
        \item UserDevice.java: Entity representing the relationship between users and their devices. \\
        \item UserDeviceId.java: Composite key entity for UserDevice relationships. \\
        \item Users.java: Entity for storing user information, such as credentials and profile data. \\
    \end{itemize}
    \item lgfollow\_server/repository : This package contains repository interfaces for interacting with the database.
    \begin{itemize}
        \item ImageRepository.java: Repository interface for database operations related to Image entities. \\
        \item PromptRepository.java: Repository interface for database operations related to Prompt entities. \\
        \item SongRepository.java: Repository interface for CRUD operations related to Song entities. \\
        \item UserDeviceRepository.java: Repository interface for managing UserDevice relationships in the database. \\
        \item UsersRepository.java: Repository interface for managing Users entities and user-related database operations. \\
    \end{itemize}
    \item lgfollow\_server/security: This package contains security configurations for authentication, authorization, and endpoint access control.
    \begin{itemize}
        \item SecurityConfig.java: Configuration for securing the application, including authentication, authorization, and endpoint access. \\
        \item WebConfig.java: Configuration for web-related settings, such as CORS policies and request/response customizations. \\
    \end{itemize}
    \item lgfollow\_server/service: This package contains business logic and services for the application.
    \begin{itemize}
        \item ImageService.java: Service for handling image-related logic, such as upload, processing, and retrieval. \\
        \item MqttPublisherService.java: Service for publishing messages to the MQTT broker. \\
        \item SongSendService.java: Service for sending song-related data to external APIs or systems. \\
        \item SongService.java: Service for managing songs, including creation, retrieval, and updates. \\
        \item UserDeviceService.java: Service for managing user-device relationships, including registration and communication. \\
        \item UsersService.java: Service for managing user-related logic, such as authentication, profile updates, and data access. \\
    \end{itemize}
\end{itemize}

\clearpage

\subsection{Module 2: AI}

\subsubsection{Purpose}
\noindent Our team has developed a multimodal deep learning model based on the BLIP architecture to generate prompts from images. BLIP is a model that connects images and text, making it possible to create descriptive and meaningful prompts from images. To enhance the accuracy of BLIP and produce richer prompts, we fine-tuned the model using the Flickr30k dataset via the Hugging Face framework. Flickr30k is a comprehensive dataset containing everyday images with detailed annotations. This fine-tuning process has improved the model's ability to interpret and describe various types of visual input, including real-world images and hand-drawn illustrations.\\

\subsubsection{Fuctionality}
\noindent The model takes an input image and generates a descriptive prompt based on its visual features. This functionality allows the user to easily extract meaningful textual descriptions from various types of images, such as real-world photos or hand-drawn sketches. The model was trained using the Flickr30k dataset, enabling it to recognize and describe a wide range of visual elements effectively.\\

\subsubsection{AI Table}

\begin{figure}[h!]
    \centering
    \includegraphics[width=1.05\linewidth]{image/AI_Table.png}
    \caption{AI Table}
    \label{fig:enter-label}
\end{figure}

\begin{itemize}
    \item BLIP (Bootstrapping Language-Image Pre-training)
\begin{itemize}
    \item The BLIP model is a multimodal model designed to connect images and text. BLIP can generate descriptive and meaningful prompts based on images.\\
    \item It is used to analyze input images and generate text prompts based on their visual features.\\
\end{itemize}
\end{itemize}

\begin{itemize}
    \item Flickr30K dataset
\begin{itemize}
    \item The Flickr30K dataset is a comprehensive dataset containing a variety of everyday images, each annotated with detailed captions.\\
    \item It was used to fine-tune the BLIP model, improving its accuracy and enhancing its ability to generate richer text prompts. By training on this dataset, the model has learned to better interpret visual elements and describe them effectively.\\
\end{itemize}
\end{itemize}

\begin{itemize}
    \item PyTorch: PyTorch was the framework used for implementing and training the deep learning model. Its integration with Hugging Face facilitated the fine-tuning process using the Flickr30K dataset.\\
\end{itemize}

\begin{itemize}
    \item Training Details
\begin{itemize}
    \item Epochs: The model was trained on the entire dataset for 3 epochs. This allows the model to sufficiently learn the patterns in the data and improve its generalization capabilities.\\
    \item Time per Epoch: Each epoch took approximately 5 hours to complete, reflecting the model's complexity and the large size of the dataset.\\
    \item Effect: These training configurations helped the model improve its ability to understand fine-grained visual details and convert them into meaningful text descriptions.\\
\end{itemize}
\end{itemize}

\begin{itemize}
    \item System Configuration
\begin{itemize}
    \item CPU: Intel Core i5 processor\\
    \item RAM: 32GB, enabling efficient processing of large datasets and fast training times.\\
\end{itemize}
\end{itemize}



\clearpage

\subsubsection{Result of Fine-turned BLIP Model}
\begin{figure}[h!]
    \centering
    \includegraphics[width=0.5\linewidth]{image/Cat.jpeg}
    \caption{Example picture}
    \label{fig:enter-label}
\end{figure}

\begin{itemize}
    \item The output caption of the original BLIP model: a cat laying on the floor.\\
    \item The output caption of the fine-tuned BLIP model: a brown cat is laying on the floor with its eyes wide open.\\
\end{itemize}


\subsubsection{Location of source code:}
\url{https://github.com/LG-Follow/AI}\\

\vspace{9cm}

\begin{table}[h!]
\caption{AI Directory Organization}
\def\arraystretch{1.4} \small
    \begin{tabular}{|p{4.1cm}|p{4.1cm}|}
        \hline
        Directory & File Name \\ \hline
        Root & .gitignore \par README.md \par requirement.txt
        \par train\_model.py \par main.py\\ \hline
        configs & blip\_config.json \par \\ \hline
        project\_directory/models \par /trained\_model & config.json \par generation\_config.json \par preprocessor\_config.json \par special\_tokens\_map.json \par tokenizer.json \par tokenizer\_config.json \par vocab.txt \\ \hline
        utils/\_\_pycache\_\_ & blip\_prompting.cpython-312.pyc \par blip\_training.cpython-312.pyc \par blip\_utils.cpython-312.pyc \par collate.cpython-312.pyc \par data\_processing.cpython-312.pyc \\ \hline
        utils & blip\_prompting.py \par blip\_training.py \par collate.py \par data\_processing.py \\ \hline
    \end{tabular}
\end{table}

\subsubsection{Class Component}
\begin{itemize}
    \item main.py: The main entry point of the project. \\
    \item train\_model.py: Script for training the BLIP model using provided configurations and datasets. \\
    \item configs: This is a directory for configuration of BLIP model training.
    \begin{itemize}
        \item blip\_config.json: Contains epoch number, architecture settings, and training configurations for BLIP. \\
    \end{itemize}
    \item project\_directory/models/trained\_model: Directory containing the trained model and associated configuration files.
    \begin{itemize}
        \item config.json: Metadata about the model, including architecture and dataset details. \\
        \item generation\_config.json: Settings for generating outputs. \\
        \item preprocessor\_config.json: Configuration for preprocessing images and input data for compatibility with the model. \\
    \end{itemize}
    \item utils: A directory for utility scripts used during training, preprocessing, and inference.
    \begin{itemize}
        \item blip\_prompting.py: Script for generating prompts from images using the BLIP model. \\
        \item blip\_training.py: Script for handling the BLIP model's training pipeline. \\
        \item collate.py: Utility for batching and collating input data during training or inference. \\
        \item data\_processing.py: Functions for processing and augmenting datasets for model training. \\
    \end{itemize}
\end{itemize}


\subsection{Module 3: Frontend}

\subsubsection{Purpose}
\noindent The Frontend leverages the Flutter framework to provide an interface that supports user interactions. This allows users to control devices, view generated content, and process data visually. It focuses on enhancing the user experience by transmitting user inputs (e.g., drawings, settings) to the backend and visually presenting the processed data returned from the backend.\\

\subsubsection{Functionality}
\noindent Users can draw on a canvas screen and send their drawings to the backend. Additionally, it offers toggle buttons to turn LG appliances' power and speakers On/Off. The application also allows users to register LG appliances in the LG Follow app via QR code scanning. Furthermore, it provides a user interface to access previously created songs and a screen to view unfinished drawings.\\

\subsubsection{Using MVVM Pattern (Model, View, ViewModel)}

\begin{figure}[h!]
    \centering
    \includegraphics[width=1.07\linewidth]{image/그림1.png}
    \caption{MVVM Pattern}
    \label{fig:enter-label}
\end{figure}
\noindent The View delivers user input to the ViewModel, which then processes the data or requests further information from the Model based on the input. Subsequently, the View subscribes to the ViewModel using tools like Providers, Streams, or state management techniques and updates the display to reflect the updated data state.\\

\begin{itemize}
    \item Advantages of MVVM Pattern
\begin{itemize}
    \item Separation of Concerns: The application is divided into distinct areas: View, ViewModel, and Model, each with specific responsibilities. This separation significantly reduces the complexity of the program.\\
    \item Ease of Testing: The clear interface between the View and ViewModel makes it easier to independently test the logic and functionality of the ViewModel.\\
    \item Structured Project Organization: The MVVM pattern organizes the application into three components: View, ViewModel, and Model, which can be developed and managed independently. This structure improves maintainability and collaboration efficiency.\\
    \item Parallel Development of UI: The separation of View and ViewModel enables simultaneous development of the UI and the ViewModel’s logic, enhancing team productivity.\\
    \item Abstraction of View: The View does not directly handle data but communicates with the ViewModel to send and receive data. The ViewModel serves as an intermediary between the UI and the business logic, reducing the coupling between them and improving maintainability.\\  
\end{itemize}
\end{itemize}

\subsubsection{Location of source code:}
\url{https://github.com/LG-Follow/Front-End}\\


\begin{table}[h!]
\caption{Frontend Directory Organization}
\def\arraystretch{1.4} \small
\begin{tabular}{|p{4.1cm}|p{4.1cm}|}
    \hline
    Directory & File Name \\ \hline
    Root & .gitignore \par .metadata \par README.md \par analysis\_options.yaml \par pubspec.lock \par pubspec.yaml\\ \hline
    android & .gitignore \par build.gradle \par gradle.properties \par settings.gradle \\ \hline
    android/app & build.gradle \\ \hline
    android/app/src/debug & AndroidManifest.xml \\ \hline
    android/app/src/main & AndroidManifest.xml \par MainActivity.kt \\ \hline
    android/app/src/main/res \par /drawable-v21 & launch\_background.xml \\ \hline
    android/app/src/main/res \par /drawable & launch\_background.xml \\ \hline
    android/app/src/main/res/mipmap-hdpi & ic\_launcher.png \\ \hline
    android/app/src/main/res/mipmap-mdpi & ic\_launcher.png \\ \hline
    android/app/src/main/res/mipmap-xhdpi & ic\_launcher.png \\ \hline
    android/app/src/main/res/mipmap-xxhdpi & ic\_launcher.png \\ \hline
    android/app/src/main/res/mipmap-xxxhdpi & ic\_launcher.png \\ \hline
    android/app/src/main/res/values-night & styles.xml \\ \hline
    android/app/src/main/res/values & styles.xml \\ \hline
    android/app/src/profile & AndroidManifest.xml \\ \hline
    assets/images & Follow.png \par Follow\_logo.png \par SoundSketch.png \par ai\_fit.png \par aircon.png \par dryer.png \par energy.png \par finger 1.png \par finger 2.png \par finger.png \par lg\_follow\_logo.png \par lg\_logo.png \par off.png \par on.png \par our\_apt.png \par ref.png \par robot.png \par sound.png \par sound\_sketch\_logo.png \par speaker.png \par tv.png \par washing.png \\ \hline
    ios & .gitignore \par Podfile \par Podfile.lock \\ \hline
    ios/Flutter & AppFrameworkInfo.plist \par Debug.xcconfig \par Release.xcconfig \\ \hline
\end{tabular}
\end{table}

\begin{table}[h!]
\caption{Frontend Directory Organization}
\def\arraystretch{1.4} \small
\begin{tabular}{|p{4.1cm}|p{4.1cm}|}
    \hline
    Directory & File Name \\ \hline
    ios/Runner & AppDelegate.swift \par Info.plist \par Runner-Bridging-Header.h \\ \hline
    ios/Runner/Assets.xcassets \par /AppIcon.appiconset & Contents.json \par Icon-App-1024x1024@1x.png \par Icon-App-20x20@1x.png \par Icon-App-20x20@2x.png \par Icon-App-20x20@3x.png \par Icon-App-29x29@1x.png \par Icon-App-29x29@2x.png \par Icon-App-29x29@3x.png \par Icon-App-40x40@1x.png \par Icon-App-40x40@2x.png \par Icon-App-40x40@3x.png \par Icon-App-60x60@2x.png \par Icon-App-60x60@3x.png \par Icon-App-76x76@1x.png \par Icon-App-76x76@2x.png \par Icon-App-83.5x83.5@2x.png \\ \hline
    ios/Runner/Assets.xcassets \par /LaunchImage.imageset & Contents.json \par LaunchImage.png \par LaunchImage@2x.png \par LaunchImage@3x.png \par README.md \\ \hline
    lib & main.dart \\ \hline
    lib/model & Drawing.dart \par Login.dart \par Point.dart \par Temp.dart \par device.dart \par drawing\_painter.dart \par home.dart \par menu.dart \par product.dart \par sketch\_home.dart \par song.dart \\ \hline
    lib/view & Drawing\_view.dart \par Follow\_view.dart \par Login\_view.dart \par Sound.dart \par Temp\_view.dart \par home\_view.dart \par menu\_view.dart \par product\_view.dart \par qr\_scan\_view.dart \par sketch\_home\_view.dart \par song\_list\_view.dart \\ \hline
    lib/viewModel & Drawing\_view\_model.dart \par Login\_view\_model.dart \par Temp\_view\_model.dart \par home\_view\_model.dart \par menu\_view\_model.dart \par product\_view\_model.dart \par qr\_scan\_view\_model.dart \par sketch\_home\_view\_model.dart \par song\_view\_model.dart \\ \hline
    linux & .gitignore \par CMakeLists.txt \\ \hline
    linux/flutter & CMakeLists.txt \par generated\_plugin\_registrant.cc \par generated\_plugin\_registrant.h \par generated\_plugins.cmake \\ \hline
\end{tabular}
\end{table}

\clearpage

\begin{table}[h!]
\caption{Frontend Directory Organization}
\def\arraystretch{1.4} \small
\begin{tabular}{|p{4.1cm}|p{4.1cm}|}
    \hline
    Directory & File Name \\ \hline
    macos & .gitignore \par Podfile \\ \hline
    macos/Flutter & Flutter-Debug.xcconfig \par Flutter-Release.xcconfig \par GeneratedPluginRegistrant.swift \\ \hline
    macos/Runner & AppDelegate.swift \par Info.plist \\ \hline
    macos/Runner/Assets.xcassets \par /AppIcon.appiconset & Contents.json \par app\_icon\_1024.png \par app\_icon\_128.png \par app\_icon\_16.png \par app\_icon\_256.png \par app\_icon\_32.png \par app\_icon\_512.png \par app\_icon\_64.png \\ \hline
    pubspec & pubspec.lock \par pubspec.yaml \\ \hline
    test & widget\_test.dart \\ \hline
    web & favicon.png \par index.html \par manifest.json \\ \hline
    web/icons & Icon-192.png \par Icon-512.png \par Icon-maskable-192.png \par Icon-maskable-512.png \\ \hline
    windows & .gitignore \par CMakeLists.txt \\ \hline
    windows/flutter & CMakeLists.txt \par generated\_plugin\_registrant.cc \par generated\_plugin\_registrant.h \par generated\_plugins.cmake \\ \hline
\end{tabular}
\end{table}

\subsubsection{Class Component}
\begin{itemize}
    \item .metadata: Contains project metadata. \\
    \item analysis\_options.yaml: Configuration for static code analysis. \\

    \item android: Contains Android-specific files and configurations.
    \begin{itemize}
        \item .gitignore: Specifies ignored files in the Android directory. \\
        \item build.gradle: Defines the Android project’s build configurations. \\
        \item gradle.properties: Configuration properties for Gradle. \\
        \item gradle-wrapper.properties: Gradle wrapper configuration file. \\
        \item settings.gradle: Settings for the Android project. \\
        \item src/debug/AndroidManifest.xml: Android manifest for the debug build. \\
        \item src/main/AndroidManifest.xml: Main Android manifest defining app configurations. \\
        \item src/main/kotlin/com/example/lg\_follow/MainActivity.kt: Entry point for the Android app. \\
        \item src/main/res/drawable-v21/launch\_background.xml: Background for the launch screen for API level 21+. \\
        \item src/main/res/drawable/launch\_background.xml: Background for the launch screen for older APIs. \\
        \item src/main/res/mipmap-\*/ic\_launcher.png: Launcher icons in different resolutions. \\
        \item src/main/res/values-night/styles.xml: Styles for night mode. \\
        \item src/main/res/values/styles.xml: Default styles for the app. \\
    \end{itemize}

    \item assets/images: Contains image assets used in the application.
    \begin{itemize}
        \item Follow.png, Follow\_logo.png: Images for branding and follow features.\\
        \item SoundSketch.png, ai\_fit.png, aircon.png, dryer.png, etc.: Miscellaneous assets representing app features or functionalities. \\
    \end{itemize}

    \item ios: Contains iOS-specific files and configurations.
    \begin{itemize}
        \item .gitignore: Specifies ignored files in the iOS directory. \\
        \item Flutter/AppFrameworkInfo.plist: Info for the Flutter framework. \\
        \item Flutter/Debug.xcconfig, Release.xcconfig: Debug and release configurations. \\
        \item Podfile, Podfile.lock: CocoaPods dependencies and lock file. \\
        \item Runner.xcodeproj: Xcode project file for the iOS app. \\
        \item Runner/AppDelegate.swift: Entry point for the iOS app. \\
        \item Runner/Assets.xcassets: Contains app icons and launch images. \\
        \item Runner/Base.lproj: Contains storyboard files for iOS UI. \\
    \end{itemize}

    \item lib: Contains the main Dart code for the application, including business logic, UI, and state management.
    \begin{itemize}
\item model: Contains data models representing the app's structure and behavior.
\begin{itemize}
    \item Drawing.dart: Defines a class for storing user-drawn sketches. \\
    \item Login.dart: Manages user login information. \\
    \item Point.dart: Represents point data in a sketch. \\
    \item Temp.dart: Manages temporarily saved data. \\
    \item device.dart: Stores information about IoT devices (e.g., speakers) to support appliance-related functionality. \\
    \item drawing\_painter.dart: Implements rendering and painting functionality for sketches. \\
    \item home.dart: Manages data related to the home screen (registered appliances). \\
    \item menu.dart: Manages menu information (e.g., option lists, icons). \\
    \item product.dart: Manages appliance addition (e.g., selecting which appliance to add). \\
    \item sketch\_home.dart: Manages data needed for the Sound Sketch home screen. \\
    \item song.dart: Manages song data such as title, URL, and creation date. \\
\end{itemize}

\item view: Contains UI components and widgets.
\begin{itemize}
    \item Drawing\_view.dart: Provides a UI for creating or editing sketches. \\
    \item Follow\_view.dart: Sets up the app's initial screen (loading screen). \\
    \item Login\_view.dart: User login screen. \\
    \item Sound.dart: Loading screen for navigating to the Sound Sketch feature. \\
    \item home\_view.dart: Implements the UI for the home screen. \\
    \item menu\_view.dart: Displays the app's menu. \\
    \item product\_view.dart: Displays a list of appliances to add. \\
    \item qr\_scan\_view.dart: QR code scanning screen. \\
    \item sketch\_home\_view.dart: Displays key features (e.g., sketches, temporary data) on the Sound Sketch home screen. \\
    \item song\_list\_view.dart: Displays a list of songs and allows users to select one. \\
\end{itemize}

\item viewModel: Contains state management and logic.
\begin{itemize}
    \item Drawing\_view\_model.dart: Handles and manages sketch data, connecting the View and Model, and converts sketches to FormData or PNG format. \\
    \item Login\_view\_model.dart: Handles login logic and user authentication. \\
    \item Temp\_view\_model.dart: Manages logic for temporarily saved data. \\
    \item home\_view\_model.dart: Manages data logic for the home screen. \\
    \item menu\_view\_model.dart: Manages logic related to menu selection. \\
    \item product\_view\_model.dart: Handles logic for adding appliances. \\
    \item qr\_scan\_view\_model.dart: Manages QR code scanning logic and processing. \\
    \item sketch\_home\_view\_model.dart: Manages data and actions for the Sound Sketch home screen. \\
    \item song\_view\_model.dart: Manages the song list and playback state, connecting the UI and Model. \\
\end{itemize}
\end{itemize}
        \end{itemize}
\begin{itemize}
    \item pubspec.yaml: Lists dependencies and assets for the project. \\
    \item test: Contains unit tests for the application. \\
    \item web: Contains web-specific files for deploying the app as a web application. \\
    \item windows: Contains Windows-specific files and configurations. \\
\end{itemize}

\section{Use Case}

\subsection{Initial Screen}
\begin{figure}[h!]
    \centering
    \includegraphics[width=0.45\linewidth]{image/InitialScreen.png}
    \caption{Initial Screen}
    \label{fig:enter-label}
\end{figure}

\noindent The LG Follow loading page briefly appears when users turn on the application. This page is displayed while the application is preparing. Once the loading is complete, it automatically transitions to the next page.\\


\subsection{Log in}
\begin{figure}[h!]
    \centering
    \includegraphics[width=0.45\linewidth]{image/Login.png}
    \caption{Log In}
    \label{fig:enter-label}
\end{figure}

\noindent Login page is a page which allows users to log in by entering their id and password.\\



\subsection{Main Page}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.45\linewidth]{image/Main.png}
    \caption{Main Page}
    \label{fig:enter-label}
\end{figure}

\noindent The main page is where users can view registered devices or register new ones using a QR code. In the center of the page, users can toggle the speaker functionality on or off for each registered device using the button next to it. Below the last listed device, the Add Appliance button enables users to scan a QR code to register a new device. The bottom navigation bar offers options to return to the main page or navigate to the menu page.\\

\clearpage

\subsection{Device Registration}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.45\linewidth]{image/QR0.png}
    \caption{Divice Registration}
    \label{fig:enter-label}
\end{figure}

\noindent Users can tap the 'Add Appliance' button to scan QR codes using their smartphone's camera. By scanning a QR code, users can register their home appliances to the application.\\


\begin{figure}[h!]
    \centering
    \includegraphics[width=0.45\linewidth]{image/QR.png}
    \caption{QR Scan}
    \label{fig:enter-label}
\end{figure}




\subsection{Menu Page}
\begin{figure}
    \centering
    \includegraphics[width=0.45\linewidth]{image/Menu.png}
    \caption{Menu Page}
    \label{fig:enter-label}
\end{figure}

\noindent Users can navigate to the menu page by tapping the menu button on the right side of the bottom navigator. In the center of the menu page, there is a 'Sound Sketch' button.
Users can tap this button to access the Sound Sketch service.\\ 


\subsection{Sound Sketch Initial Screen}
\begin{figure}[h!]
    \centering
    \includegraphics[width=0.45\linewidth]{image/SoundSketch1.png}
    \caption{Enter Sound Sketch}
    \label{fig:enter-label}
\end{figure}

\noindent The Sound Sketch loading page briefly appears when users click on Sound Sketch from the main page. This page is displayed while the application is preparing. Once the loading is complete, it automatically transitions to the next page.\\

\clearpage

\subsection{Sound Sketch Main Page}
\begin{figure}[h!]
    \centering
    \includegraphics[width=0.45\linewidth]{image/SoundSketch2.png}
    \caption{Sound Sketch Main Page }
    \label{fig:enter-label}
\end{figure}

\noindentThe Sound Sketch main page consists of three main sections. At the top, the Quick Playlist section displays previously created drawings and their associated music as thumbnails with labels, allowing users to view details or play the music. In the center, the Temporary Storage section shows saved but unfinished drawings, which users can resume by tapping the thumbnail. At the bottom, dragging up the 'Drag Up to Start' area opens a canvas where users can create new drawings.\\


\subsection{Sketch Page}
\begin{figure}[h!]
    \centering
    \includegraphics[width=0.45\linewidth]{image/SoundSketch3.png}
    \caption{Sketch Page}
    \label{fig:enter-label}
\end{figure}

\noindentOn The Sketch page, users can draw on the central canvas, selecting from a variety of brush thicknesses and colors to create their artwork. The Delete button at the top lets users erase their current drawing, and the Submit button to its right enables them to generate music from their drawing. Additionally, by clicking the File icon, users can attach an image file, allowing them to import a pre-made image and use it for music generation.\\


\section{Discussion}

\subsubsection{Technical Difficulties}
Our goal was to play a song created with Sound Sketch on the NUGU AI Speaker and then transfer the sound output to a speaker connected to a Raspberry Pi. However, we faced several difficulties in implementing this functionality. Despite our efforts to resolve the issue using NUGU Playbuilder and the NUGU SDK, we were unable to achieve the desired outcome.

One of the primary challenges was the lack of direct support for routing the audio output from the NUGU AI Speaker to an external speaker via Raspberry Pi. Although both NUGU Playbuilder and the NUGU SDK offer robust capabilities for building and managing AI speaker interactions, they did not provide a seamless solution for audio output redirection to another device in this particular setup.

We explored various alternatives and potential workarounds, but the solution remained elusive due to technical limitations in the software and hardware configuration. This experience highlighted the importance of ensuring compatibility and support across all integrated technologies when planning a multi-device setup. Moving forward, we would explore different approaches, such as using alternative software or hardware solutions, to better facilitate this integration.

Ultimately, while the project presented technical challenges, it also offered valuable insights into the complexities of working with multiple technologies simultaneously. This experience will guide future projects where similar integrations are required.\\

\subsubsection{Conclusion}
Currently, LG Follow is implemented by connecting PIR sensors and speakers to a Raspberry Pi to track the user's location and seamlessly switch the sound to the speaker in the room where the user is present.

However, this technology is just the beginning. If speakers are embedded into home appliances and NFC is utilized, audio will seamlessly blend into our daily lives, creating a more immersive experience.

LG Follow is not just about moving sound from one place to another. This technology has the potential to expand the scope of smart home systems into the realm of sound. We hope that LG Follow will further enhance expectations for the future of smart home technology.

\clearpage

\onecolumn
\appendix

\section{Architecture Design}
\begin{figure}[h!]
    \centering
    \includegraphics[width=18cm,height=\paperheight,keepaspectratio]{image/Arichitecture.png}
    \label{fig:fullpage}
\end{figure}

\begin{thebibliography}{00}
\bibitem{b1} Li, Junnan et al. (2022). BLIP: Bootstrapped Language-Image Pre-training for Unified Vision-Language Understanding and Generation. Retrieved from https://huggingface.co/Salesforce/blip-image-captioning-base\\
\bibitem{b2} Plummer, B.A., Wang, L., Cervantes, C.M., et al. (2015). Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models. Retrieved from https://huggingface.co/datasets/nlphuji/flickr30k\\
\bibitem{b3} Amazon RDS Free Tier. (n.d.). Retrieved from https://aws.amazon.com/free/database/\\
\bibitem{b4} CUDA Toolkit. (n.d.). Retrieved from https://developer.nvidia.com/cuda-toolkit\\
\bibitem{b5} Figma. (n.d.). Retrieved from https://www.figma.com/\\
\bibitem{b6} Flask. (2023). Retrieved from https://flask.palletsprojects.com/en/3.0.x/\\
\bibitem{b7} Flutter. (n.d.). Retrieved from https://flutter.dev\\
\bibitem{b8} Flow. (n.d.). Retrieved from https://flow.team/kr/index\\
\bibitem{b9} GitHub. (n.d.). Retrieved from https://github.com/\\
\bibitem{b10} Kafka. (n.d.). Retrieved from https://kafka.apache.org\\
\bibitem{b11}LG ThinQ. (n.d.). Retrieved from https://www.lge.co.kr/lg-thinq\\
\bibitem{b12}MySQL. (n.d.). Retrieved from https://www.mysql.com\\
\bibitem{b13} Pillow. (n.d.). Retrieved from https://python-pillow.org\\
\bibitem{b14} PyTorch. (n.d.). Retrieved from https://pytorch.org\\
\bibitem{b15} scikit-learn. (n.d.). Retrieved from https://scikit-learn.org/stable/\\
\bibitem{b16} Spring Boot. (2023). Retrieved from https://spring.io/projects/spring-boot\\
\bibitem{b17} TensorFlow. (n.d.). Retrieved from https://www.tensorflow.org
\end{thebibliography}








\end{document}
